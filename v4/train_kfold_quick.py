"""
KæŠ˜äº¤å‰éªŒè¯ - å¿«é€Ÿæµ‹è¯•ç‰ˆæœ¬
ç”¨äºéªŒè¯æµç¨‹æ˜¯å¦æ­£ç¡®ï¼Œä½¿ç”¨è¾ƒå°‘çš„epochs
"""
import os
import shutil
import random
from pathlib import Path
import torch
import yaml
from sklearn.model_selection import KFold
from ultralytics import YOLO
import numpy as np


# ==========================================
# 1. é…ç½®å‚æ•°
# ==========================================
ORIGINAL_DATASET = r".\Data\dataset_merged_no_noise"
KFOLD_DATASET_ROOT = r".\Data\dataset_kfold_quick"
MODEL_CONFIG = "./yolo11P.yaml"
PRETRAINED_WEIGHTS = "./yolo11n.pt"
DEVICE = '0' if torch.cuda.is_available() else 'cpu'
K_FOLDS = 3  # å¿«é€Ÿæµ‹è¯•ä½¿ç”¨3æŠ˜
RANDOM_SEED = 42
EPOCHS = 10  # å¿«é€Ÿæµ‹è¯•ä½¿ç”¨10ä¸ªepochs


def prepare_kfold_dataset():
    """
    å‡†å¤‡KæŠ˜äº¤å‰éªŒè¯çš„æ•°æ®é›†
    
    âš ï¸ é‡è¦è¯´æ˜ï¼š
    - KæŠ˜äº¤å‰éªŒè¯åªä½¿ç”¨ train + val æ•°æ®
    - testæ•°æ®é›†å®Œå…¨ç‹¬ç«‹ï¼Œä¸å‚ä¸KæŠ˜åˆ’åˆ†
    - testæ•°æ®é›†åªåœ¨æœ€åç”¨äºè¯„ä¼°æœ€ç»ˆæ¨¡å‹æ€§èƒ½
    """
    print("\nğŸ“‚ å‡†å¤‡KæŠ˜äº¤å‰éªŒè¯æ•°æ®é›†...")
    print("âš ï¸  æ³¨æ„ï¼šåªåˆå¹¶ train + valï¼Œtesté›†ä¿æŒç‹¬ç«‹ï¼")
    
    train_images = list(Path(ORIGINAL_DATASET).glob("images/train/*"))
    val_images = list(Path(ORIGINAL_DATASET).glob("images/val/*"))
    test_images = list(Path(ORIGINAL_DATASET).glob("images/test/*"))
    
    # âœ… KæŠ˜åªä½¿ç”¨train+val
    all_images = train_images + val_images
    
    print(f"âœ… Trainé›†: {len(train_images)} å¼ ")
    print(f"âœ… Valé›†: {len(val_images)} å¼ ")
    print(f"âœ… ç”¨äºKæŠ˜: {len(all_images)} å¼  (train+valåˆå¹¶)")
    print(f"ğŸ”’ Testé›†: {len(test_images)} å¼  (ä¿ç•™ï¼Œä¸å‚ä¸KæŠ˜)")
    
    image_files = [img_path.stem for img_path in all_images]
    return image_files


def create_fold_dataset(image_files, train_indices, val_indices, fold_num):
    """ä¸ºç‰¹å®šfoldåˆ›å»ºæ•°æ®é›†"""
    fold_dir = Path(KFOLD_DATASET_ROOT) / f"fold_{fold_num}"
    
    # åˆ›å»ºç›®å½•
    for split in ['train', 'val']:
        (fold_dir / 'images' / split).mkdir(parents=True, exist_ok=True)
        (fold_dir / 'labels' / split).mkdir(parents=True, exist_ok=True)
    
    # å¤åˆ¶æ–‡ä»¶
    def copy_files(indices, split):
        for idx in indices:
            img_name = image_files[idx]
            src_img = None
            src_label = None
            
            for source_split in ['train', 'val']:
                for ext in ['.jpg', '.png', '.jpeg', '.JPG', '.PNG']:
                    img_path = Path(ORIGINAL_DATASET) / 'images' / source_split / f"{img_name}{ext}"
                    if img_path.exists():
                        src_img = img_path
                        break
                if src_img:
                    label_path = Path(ORIGINAL_DATASET) / 'labels' / source_split / f"{img_name}.txt"
                    if label_path.exists():
                        src_label = label_path
                    break
            
            if src_img:
                dst_img = fold_dir / 'images' / split / src_img.name
                shutil.copy2(src_img, dst_img)
                if src_label:
                    dst_label = fold_dir / 'labels' / split / f"{img_name}.txt"
                    shutil.copy2(src_label, dst_label)
    
    copy_files(train_indices, 'train')
    copy_files(val_indices, 'val')
    
    # åˆ›å»ºdataset.yaml
    dataset_yaml = {'path': str(fold_dir.absolute()), 'train': 'images/train', 'val': 'images/val'}
    
    original_yaml_path = Path(ORIGINAL_DATASET) / 'dataset.yaml'
    if original_yaml_path.exists():
        with open(original_yaml_path, 'r', encoding='utf-8') as f:
            original_config = yaml.safe_load(f)
            dataset_yaml.update({k: original_config[k] for k in ['names', 'nc'] if k in original_config})
    
    yaml_path = fold_dir / 'dataset.yaml'
    with open(yaml_path, 'w', encoding='utf-8') as f:
        yaml.dump(dataset_yaml, f, sort_keys=False)
    
    return str(yaml_path)


def train_single_fold(fold_num, dataset_yaml, results_dir):
    """è®­ç»ƒå•ä¸ªfold"""
    print(f"\nğŸš€ å¼€å§‹è®­ç»ƒ Fold {fold_num}")
    
    model = YOLO(MODEL_CONFIG)
    
    try:
        model.load(PRETRAINED_WEIGHTS)
        print("âœ… åŠ è½½é¢„è®­ç»ƒæƒé‡")
    except Exception as e:
        print(f"âš ï¸ æƒé‡åŠ è½½è·³è¿‡: {e}")
    
    def freeze_dino_on_train_start(trainer):
        frozen_count = 0
        for name, param in trainer.model.named_parameters():
            if ".dino." in name and param.requires_grad:
                param.requires_grad = False
                frozen_count += 1
        print(f"âœ… å·²å†»ç»“ {frozen_count} ä¸ª DINO å‚æ•°")
    
    model.add_callback("on_train_start", freeze_dino_on_train_start)
    
    # è®­ç»ƒï¼ˆä½¿ç”¨è¾ƒå°‘çš„epochsï¼‰
    results = model.train(
        data=dataset_yaml,
        epochs=EPOCHS,  # å¿«é€Ÿæµ‹è¯•
        imgsz=640,
        batch=16,  # è¾ƒå°batch
        patience=0,
        optimizer='AdamW',
        amp=False,
        cos_lr=True,
        lr0=0.0005,
        lrf=0.01,
        warmup_epochs=2.0,  # å‡å°‘warmup
        device=DEVICE,
        plots=False,  # ä¸ç”Ÿæˆå›¾è¡¨ä»¥èŠ‚çœæ—¶é—´
        project=results_dir,
        name=f'fold_{fold_num}',
        exist_ok=True,
    )
    
    # éªŒè¯ï¼ˆåœ¨å½“å‰foldçš„éªŒè¯é›†ä¸Šï¼‰
    best_model_path = Path(results.save_dir) / 'weights' / 'best.pt'
    best_model = YOLO(best_model_path)
    metrics = best_model.val(
        data=dataset_yaml,
        split='val',
        imgsz=640,
        batch=16,
        device=DEVICE,
        project=results_dir,
        name=f'fold_{fold_num}_val',
        exist_ok=True
    )
    
    return {
        'fold': fold_num,
        'mAP50': float(metrics.box.map50),
        'mAP50-95': float(metrics.box.map),
        'precision': float(metrics.box.p.mean()),
        'recall': float(metrics.box.r.mean()),
        'best_weights': str(best_model_path),  # ä¿å­˜æƒé‡è·¯å¾„
    }


def run_kfold_cross_validation():
    """æ‰§è¡ŒKæŠ˜äº¤å‰éªŒè¯"""
    random.seed(RANDOM_SEED)
    np.random.seed(RANDOM_SEED)
    torch.manual_seed(RANDOM_SEED)
    
    print(f"\nğŸ¯ å¼€å§‹ {K_FOLDS} æŠ˜äº¤å‰éªŒè¯ï¼ˆå¿«é€Ÿæµ‹è¯•ç‰ˆ - {EPOCHS} epochsï¼‰")
    
    image_files = prepare_kfold_dataset()
    kfold = KFold(n_splits=K_FOLDS, shuffle=True, random_state=RANDOM_SEED)
    all_results = []
    results_base_dir = Path("runs") / "kfold_quick"
    results_base_dir.mkdir(parents=True, exist_ok=True)
    
    for fold_num, (train_idx, val_idx) in enumerate(kfold.split(image_files), 1):
        print(f"\nğŸ“Š Fold {fold_num}/{K_FOLDS}")
        dataset_yaml = create_fold_dataset(image_files, train_idx, val_idx, fold_num)
        fold_result = train_single_fold(fold_num, dataset_yaml, str(results_base_dir))
        all_results.append(fold_result)
        
        print(f"  mAP50: {fold_result['mAP50']:.4f} | mAP50-95: {fold_result['mAP50-95']:.4f}")
    
    # ==========================================
    # KæŠ˜äº¤å‰éªŒè¯æ±‡æ€»
    # ==========================================
    print("\n" + "="*70)
    print("ğŸ“ˆ KæŠ˜äº¤å‰éªŒè¯æ±‡æ€»ç»“æœ (åœ¨å„foldçš„éªŒè¯é›†ä¸Š)")
    print("="*70)
    for metric in ['mAP50', 'mAP50-95', 'precision', 'recall']:
        values = [r[metric] for r in all_results]
        print(f"{metric:<12}: {np.mean(values):.4f} Â± {np.std(values):.4f}")
    
    # é€‰æ‹©æœ€ä½³fold
    best_fold = max(all_results, key=lambda x: x['mAP50-95'])
    print(f"\nğŸ† æœ€ä½³ Fold: Fold {best_fold['fold']} (mAP50-95: {best_fold['mAP50-95']:.4f})")
    
    # ==========================================
    # æœ€ç»ˆæµ‹è¯•é›†è¯„ä¼°ï¼ˆé‡è¦ï¼ï¼‰
    # ==========================================
    print("\n" + "="*70)
    print("ğŸ¯ æœ€ç»ˆè¯„ä¼°ï¼šåœ¨ç‹¬ç«‹æµ‹è¯•é›†ä¸Šè¯„ä¼°æœ€ä½³æ¨¡å‹")
    print("="*70)
    print("âš ï¸  è¿™æ˜¯æ¨¡å‹çš„æœ€ç»ˆæ€§èƒ½ï¼Œç”¨äºè®ºæ–‡æŠ¥å‘Šï¼")
    
    # ä½¿ç”¨æœ€ä½³foldçš„æ¨¡å‹åœ¨åŸå§‹æµ‹è¯•é›†ä¸Šè¯„ä¼°
    best_model = YOLO(best_fold['best_weights'])
    test_metrics = best_model.val(
        data=str(Path(ORIGINAL_DATASET) / 'dataset.yaml'),
        split='test',  # ä½¿ç”¨ç‹¬ç«‹çš„testé›†
        imgsz=640,
        batch=16,
        device=DEVICE,
        project=str(results_base_dir),
        name='final_test',
        exist_ok=True
    )
    
    print("\n" + "="*70)
    print("ğŸ“Š æœ€ç»ˆæµ‹è¯•é›†ç»“æœ (ç”¨äºè®ºæ–‡æŠ¥å‘Š):")
    print("="*70)
    print(f"mAP50:        {test_metrics.box.map50:.4f}")
    print(f"mAP50-95:     {test_metrics.box.map:.4f}")
    print(f"Precision:    {test_metrics.box.p.mean():.4f}")
    print(f"Recall:       {test_metrics.box.r.mean():.4f}")
    print("="*70)
    
    print("\nğŸ’¡ ç†è§£è¿™äº›ç»“æœ:")
    print("  - KæŠ˜äº¤å‰éªŒè¯ç»“æœ: ç”¨äºé€‰æ‹©æœ€ä½³æ¨¡å‹/è¶…å‚æ•°")
    print("  - æµ‹è¯•é›†ç»“æœ: æ¨¡å‹çš„çœŸå®æ³›åŒ–èƒ½åŠ›ï¼ŒæŠ¥å‘Šè¿™ä¸ªï¼")
    
    return all_results, test_metrics


if __name__ == "__main__":
    kfold_results, final_test_metrics = run_kfold_cross_validation()
    
    print("\nâœ… KæŠ˜äº¤å‰éªŒè¯å®Œæˆï¼")
    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: runs/kfold_quick/")
