import os
import shutil
import random
from pathlib import Path
import torch
import yaml
from sklearn.model_selection import KFold
from ultralytics import YOLO
import numpy as np


# ==========================================
# 1. é…ç½®å‚æ•°
# ==========================================
# åŸå§‹æ•°æ®é›†è·¯å¾„
ORIGINAL_DATASET = r"f:\è¯¾è®¾\Machine_Learning\Data\dataset_yolo"
# KæŠ˜å·¥ä½œç›®å½•
KFOLD_DATASET_ROOT = r"f:\è¯¾è®¾\Machine_Learning\Data\dataset_kfold"
# æ¨¡å‹é…ç½®
MODEL_CONFIG = "./yolo11P.yaml"
PRETRAINED_WEIGHTS = "./yolo11n.pt"
# è®¾å¤‡
DEVICE = '0' if torch.cuda.is_available() else 'cpu'
# KæŠ˜æ•°
K_FOLDS = 5
# éšæœºç§å­
RANDOM_SEED = 42


# ==========================================
# 2. æ•°æ®é›†å‡†å¤‡å‡½æ•°
# ==========================================
def prepare_kfold_dataset():
    """
    å‡†å¤‡KæŠ˜äº¤å‰éªŒè¯çš„æ•°æ®é›†ç»“æ„
    
    âš ï¸ é‡è¦è¯´æ˜ï¼š
    - KæŠ˜äº¤å‰éªŒè¯åªä½¿ç”¨ train + val æ•°æ®
    - testæ•°æ®é›†å®Œå…¨ç‹¬ç«‹ï¼Œä¸å‚ä¸KæŠ˜åˆ’åˆ†  
    - testæ•°æ®é›†åªåœ¨æœ€åç”¨äºè¯„ä¼°æœ€ç»ˆæ¨¡å‹æ€§èƒ½
    
    å°†åŸå§‹train/valæ•°æ®åˆå¹¶ï¼Œç”¨äºKæŠ˜åˆ’åˆ†
    """
    print("\n" + "="*50)
    print("ğŸ“‚ å‡†å¤‡KæŠ˜äº¤å‰éªŒè¯æ•°æ®é›†...")
    print("="*50)
    print("âš ï¸  æ³¨æ„ï¼šåªåˆå¹¶ train + valï¼Œtesté›†ä¿æŒç‹¬ç«‹ç”¨äºæœ€ç»ˆè¯„ä¼°ï¼")
    
    # æ”¶é›†è®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•å›¾åƒ
    train_images = list(Path(ORIGINAL_DATASET).glob("images/train/*"))
    val_images = list(Path(ORIGINAL_DATASET).glob("images/val/*"))
    test_images = list(Path(ORIGINAL_DATASET).glob("images/test/*"))
    
    # âœ… KæŠ˜åªä½¿ç”¨train+valåˆå¹¶çš„æ•°æ®
    all_images = train_images + val_images
    
    print(f"âœ… Trainé›†: {len(train_images)} å¼ è®­ç»ƒå›¾åƒ")
    print(f"âœ… Valé›†: {len(val_images)} å¼ éªŒè¯å›¾åƒ")
    print(f"âœ… ç”¨äºKæŠ˜: {len(all_images)} å¼ å›¾åƒ (train+valåˆå¹¶)")
    print(f"ğŸ”’ Testé›†: {len(test_images)} å¼ å›¾åƒ (ä¿ç•™ï¼Œä¸å‚ä¸KæŠ˜)")
    
    # æå–å›¾åƒè·¯å¾„ï¼ˆç›¸å¯¹äºimagesç›®å½•ï¼‰
    image_files = []
    for img_path in all_images:
        # è·å–æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
        img_stem = img_path.stem
        image_files.append(img_stem)
    
    return image_files


def create_fold_dataset(image_files, train_indices, val_indices, fold_num):
    """
    ä¸ºç‰¹å®šfoldåˆ›å»ºæ•°æ®é›†
    
    Args:
        image_files: æ‰€æœ‰å›¾åƒæ–‡ä»¶ååˆ—è¡¨
        train_indices: è®­ç»ƒé›†ç´¢å¼•
        val_indices: éªŒè¯é›†ç´¢å¼•
        fold_num: å½“å‰foldç¼–å·
    """
    fold_dir = Path(KFOLD_DATASET_ROOT) / f"fold_{fold_num}"
    
    # åˆ›å»ºç›®å½•ç»“æ„
    for split in ['train', 'val']:
        (fold_dir / 'images' / split).mkdir(parents=True, exist_ok=True)
        (fold_dir / 'labels' / split).mkdir(parents=True, exist_ok=True)
    
    # å¤åˆ¶æ–‡ä»¶
    def copy_files(indices, split):
        for idx in indices:
            img_name = image_files[idx]
            
            # æŸ¥æ‰¾æºæ–‡ä»¶ï¼ˆå¯èƒ½åœ¨trainæˆ–valç›®å½•ï¼‰
            src_img = None
            src_label = None
            
            for source_split in ['train', 'val']:
                # å°è¯•ä¸åŒçš„å›¾åƒæ‰©å±•å
                for ext in ['.jpg', '.png', '.jpeg', '.JPG', '.PNG']:
                    img_path = Path(ORIGINAL_DATASET) / 'images' / source_split / f"{img_name}{ext}"
                    if img_path.exists():
                        src_img = img_path
                        break
                if src_img:
                    # æ‰¾åˆ°å¯¹åº”çš„æ ‡ç­¾
                    label_path = Path(ORIGINAL_DATASET) / 'labels' / source_split / f"{img_name}.txt"
                    if label_path.exists():
                        src_label = label_path
                    break
            
            if src_img:
                # å¤åˆ¶å›¾åƒ
                dst_img = fold_dir / 'images' / split / src_img.name
                shutil.copy2(src_img, dst_img)
                
                # å¤åˆ¶æ ‡ç­¾ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                if src_label:
                    dst_label = fold_dir / 'labels' / split / f"{img_name}.txt"
                    shutil.copy2(src_label, dst_label)
    
    print(f"\nğŸ“ åˆ›å»º Fold {fold_num} æ•°æ®é›†...")
    copy_files(train_indices, 'train')
    print(f"  âœ… å¤åˆ¶ {len(train_indices)} å¼ è®­ç»ƒå›¾åƒ")
    copy_files(val_indices, 'val')
    print(f"  âœ… å¤åˆ¶ {len(val_indices)} å¼ éªŒè¯å›¾åƒ")
    
    # åˆ›å»ºdataset.yaml
    dataset_yaml = {
        'path': str(fold_dir.absolute()),
        'train': 'images/train',
        'val': 'images/val',
        'nc': 1,  # æ ¹æ®æ‚¨çš„å®é™…ç±»åˆ«æ•°ä¿®æ”¹
        'names': []  # ä¼šä»åŸå§‹dataset.yamlè¯»å–
    }
    
    # è¯»å–åŸå§‹dataset.yamlè·å–ç±»åˆ«åç§°
    original_yaml_path = Path(ORIGINAL_DATASET) / 'dataset.yaml'
    if original_yaml_path.exists():
        with open(original_yaml_path, 'r', encoding='utf-8') as f:
            original_config = yaml.safe_load(f)
            if 'names' in original_config:
                dataset_yaml['names'] = original_config['names']
            if 'nc' in original_config:
                dataset_yaml['nc'] = original_config['nc']
    
    yaml_path = fold_dir / 'dataset.yaml'
    with open(yaml_path, 'w', encoding='utf-8') as f:
        yaml.dump(dataset_yaml, f, sort_keys=False)
    
    return str(yaml_path)


# ==========================================
# 3. è®­ç»ƒå‡½æ•°
# ==========================================
def train_single_fold(fold_num, dataset_yaml, results_dir):
    """
    è®­ç»ƒå•ä¸ªfold
    
    Args:
        fold_num: foldç¼–å·
        dataset_yaml: æ•°æ®é›†é…ç½®æ–‡ä»¶è·¯å¾„
        results_dir: ç»“æœä¿å­˜ç›®å½•
    """
    print("\n" + "="*50)
    print(f"ğŸš€ å¼€å§‹è®­ç»ƒ Fold {fold_num}")
    print("="*50)
    
    # åˆå§‹åŒ–æ¨¡å‹
    model = YOLO(MODEL_CONFIG)
    
    # åŠ è½½é¢„è®­ç»ƒæƒé‡
    try:
        model.load(PRETRAINED_WEIGHTS)
        print("âœ… æˆåŠŸåŠ è½½é¢„è®­ç»ƒæƒé‡ï¼")
    except Exception as e:
        print(f"âš ï¸ åŠ è½½æƒé‡è·³è¿‡æˆ–å‡ºé”™: {e}")
    
    # å†»ç»“DINOå‚æ•°çš„å›è°ƒ
    def freeze_dino_on_train_start(trainer):
        """è®­ç»ƒå¼€å§‹æ—¶å†»ç»“DINOå‚æ•°"""
        print("ğŸ”§ [Callback] å†»ç»“ DINO å‚æ•°...")
        frozen_count = 0
        unfrozen_count = 0
        
        for name, param in trainer.model.named_parameters():
            if ".dino." in name and param.requires_grad:
                param.requires_grad = False
                frozen_count += 1
            elif any(x in name for x in ['input_projection', 'fusion_layer', 
                                         'feature_adapter', 'spatial_projection']):
                if not param.requires_grad:
                    param.requires_grad = True
                unfrozen_count += 1
        
        print(f"âœ… å·²å†»ç»“ {frozen_count} ä¸ª DINO æ¨¡å‹å‚æ•°")
        print(f"âœ… ä¿æŒ {unfrozen_count} ä¸ªèåˆå±‚å‚æ•°å¯è®­ç»ƒ")
    
    model.add_callback("on_train_start", freeze_dino_on_train_start)
    
    # è®­ç»ƒ
    results = model.train(
        data=dataset_yaml,
        epochs=50,
        imgsz=640,
        batch=32,
        patience=0,
        optimizer='AdamW',
        amp=False,
        cos_lr=True,
        lr0=0.0005,
        lrf=0.01,
        warmup_epochs=5.0,
        translate=0.05,
        scale=0.1,
        copy_paste=0.4,
        device=DEVICE,
        plots=True,
        dropout=0.2,
        project=results_dir,
        name=f'fold_{fold_num}',
        exist_ok=True,
    )
    
    # éªŒè¯
    print(f"\nğŸ” éªŒè¯ Fold {fold_num}...")
    best_model_path = Path(results.save_dir) / 'weights' / 'best.pt'
    best_model = YOLO(best_model_path)
    
    metrics = best_model.val(
        data=dataset_yaml,
        split='val',
        imgsz=640,
        batch=16,
        device=DEVICE
    )
    
    # è¿”å›å…³é”®æŒ‡æ ‡
    return {
        'fold': fold_num,
        'mAP50': float(metrics.box.map50),
        'mAP50-95': float(metrics.box.map),
        'precision': float(metrics.box.p.mean()),
        'recall': float(metrics.box.r.mean()),
        'best_weights': str(best_model_path)
    }


# ==========================================
# 4. ä¸»å‡½æ•°ï¼šKæŠ˜äº¤å‰éªŒè¯
# ==========================================
def run_kfold_cross_validation():
    """
    æ‰§è¡ŒKæŠ˜äº¤å‰éªŒè¯
    """
    # è®¾ç½®éšæœºç§å­
    random.seed(RANDOM_SEED)
    np.random.seed(RANDOM_SEED)
    torch.manual_seed(RANDOM_SEED)
    
    print("\n" + "="*70)
    print(f"ğŸ¯ å¼€å§‹ {K_FOLDS} æŠ˜äº¤å‰éªŒè¯")
    print("="*70)
    
    # å‡†å¤‡æ•°æ®é›†
    image_files = prepare_kfold_dataset()
    
    # KæŠ˜åˆ’åˆ†
    kfold = KFold(n_splits=K_FOLDS, shuffle=True, random_state=RANDOM_SEED)
    
    # å­˜å‚¨æ¯ä¸ªfoldçš„ç»“æœ
    all_results = []
    
    # ç»“æœä¿å­˜ç›®å½•
    results_base_dir = Path("runs") / "kfold_experiments"
    results_base_dir.mkdir(parents=True, exist_ok=True)
    
    # éå†æ¯ä¸ªfold
    for fold_num, (train_idx, val_idx) in enumerate(kfold.split(image_files), 1):
        print(f"\n{'='*70}")
        print(f"ğŸ“Š å¤„ç† Fold {fold_num}/{K_FOLDS}")
        print(f"{'='*70}")
        
        # åˆ›å»ºfoldæ•°æ®é›†
        dataset_yaml = create_fold_dataset(
            image_files, 
            train_idx, 
            val_idx, 
            fold_num
        )
        
        # è®­ç»ƒ
        fold_result = train_single_fold(
            fold_num, 
            dataset_yaml, 
            str(results_base_dir)
        )
        
        all_results.append(fold_result)
        
        # æ‰“å°å½“å‰foldç»“æœ
        print(f"\n{'='*50}")
        print(f"Fold {fold_num} ç»“æœ:")
        print(f"  mAP50:     {fold_result['mAP50']:.4f}")
        print(f"  mAP50-95:  {fold_result['mAP50-95']:.4f}")
        print(f"  Precision: {fold_result['precision']:.4f}")
        print(f"  Recall:    {fold_result['recall']:.4f}")
        print(f"{'='*50}")
    
    # ==========================================
    # 5. æ±‡æ€»ç»“æœ
    # ==========================================
    print("\n\n" + "="*70)
    print("ğŸ“ˆ KæŠ˜äº¤å‰éªŒè¯æ±‡æ€»ç»“æœ")
    print("="*70)
    
    # è®¡ç®—å¹³å‡å€¼å’Œæ ‡å‡†å·®
    metrics_names = ['mAP50', 'mAP50-95', 'precision', 'recall']
    
    print(f"\n{'Metric':<15} {'Mean':<10} {'Std':<10} {'Min':<10} {'Max':<10}")
    print("-" * 60)
    
    summary = {}
    for metric in metrics_names:
        values = [r[metric] for r in all_results]
        mean_val = np.mean(values)
        std_val = np.std(values)
        min_val = np.min(values)
        max_val = np.max(values)
        
        summary[metric] = {
            'mean': mean_val,
            'std': std_val,
            'min': min_val,
            'max': max_val
        }
        
        print(f"{metric:<15} {mean_val:<10.4f} {std_val:<10.4f} {min_val:<10.4f} {max_val:<10.4f}")
    
    # é€foldè¯¦ç»†ç»“æœ
    print("\n" + "="*70)
    print("å„Foldè¯¦ç»†ç»“æœ (åœ¨å„è‡ªéªŒè¯é›†ä¸Š):")
    print("="*70)
    for result in all_results:
        print(f"\nFold {result['fold']}:")
        for metric in metrics_names:
            print(f"  {metric:<12}: {result[metric]:.4f}")
    
    # ä¿å­˜æ±‡æ€»ç»“æœåˆ°æ–‡ä»¶
    summary_file = results_base_dir / "kfold_summary.yaml"
    with open(summary_file, 'w', encoding='utf-8') as f:
        yaml.dump({
            'k_folds': K_FOLDS,
            'summary': summary,
            'fold_results': all_results
        }, f, sort_keys=False)
    
    print(f"\nâœ… KæŠ˜äº¤å‰éªŒè¯æ±‡æ€»å·²ä¿å­˜åˆ°: {summary_file}")
    
    # æ‰¾å‡ºæœ€ä½³fold
    best_fold = max(all_results, key=lambda x: x['mAP50-95'])
    print(f"\nğŸ† æœ€ä½³ Fold: Fold {best_fold['fold']}")
    print(f"   mAP50-95: {best_fold['mAP50-95']:.4f}")
    print(f"   æƒé‡è·¯å¾„: {best_fold['best_weights']}")
    
    # ==========================================
    # 6. æœ€ç»ˆæµ‹è¯•é›†è¯„ä¼°ï¼ˆé‡è¦ï¼ï¼‰
    # ==========================================
    print("\n\n" + "="*70)
    print("ğŸ¯ æœ€ç»ˆè¯„ä¼°ï¼šåœ¨ç‹¬ç«‹æµ‹è¯•é›†ä¸Šè¯„ä¼°æœ€ä½³æ¨¡å‹")
    print("="*70)
    print("âš ï¸  è¿™æ˜¯æ¨¡å‹çš„æœ€ç»ˆæ€§èƒ½ï¼Œç”¨äºè®ºæ–‡æŠ¥å‘Šï¼")
    print("ğŸ“Œ  æµ‹è¯•é›†ä»æœªå‚ä¸KæŠ˜åˆ’åˆ†å’Œè®­ç»ƒè¿‡ç¨‹")
    
    # ä½¿ç”¨æœ€ä½³foldçš„æ¨¡å‹åœ¨åŸå§‹ç‹¬ç«‹æµ‹è¯•é›†ä¸Šè¯„ä¼°
    best_model = YOLO(best_fold['best_weights'])
    test_metrics = best_model.val(
        data=str(Path(ORIGINAL_DATASET) / 'dataset.yaml'),
        split='test',  # ä½¿ç”¨å®Œå…¨ç‹¬ç«‹çš„testé›†
        imgsz=640,
        batch=16,
        device=DEVICE
    )
    
    # æ‰“å°æœ€ç»ˆæµ‹è¯•é›†ç»“æœ
    print("\n" + "="*70)
    print("ğŸ“Š æœ€ç»ˆæµ‹è¯•é›†ç»“æœ (ç”¨äºè®ºæ–‡æŠ¥å‘Š):")
    print("="*70)
    print(f"mAP50:        {test_metrics.box.map50:.4f}")
    print(f"mAP50-95:     {test_metrics.box.map:.4f}")
    print(f"Precision:    {test_metrics.box.p.mean():.4f}")
    print(f"Recall:       {test_metrics.box.r.mean():.4f}")
    print("="*70)
    
    # ä¿å­˜æµ‹è¯•é›†ç»“æœ
    test_summary = {
        'test_set_results': {
            'mAP50': float(test_metrics.box.map50),
            'mAP50-95': float(test_metrics.box.map),
            'precision': float(test_metrics.box.p.mean()),
            'recall': float(test_metrics.box.r.mean()),
        },
        'best_model': best_fold['best_weights'],
        'best_fold': best_fold['fold']
    }
    
    test_summary_file = results_base_dir / "final_test_results.yaml"
    with open(test_summary_file, 'w', encoding='utf-8') as f:
        yaml.dump(test_summary, f, sort_keys=False)
    
    print(f"\nâœ… æµ‹è¯•é›†ç»“æœå·²ä¿å­˜åˆ°: {test_summary_file}")
    
    print("\nğŸ’¡ å¦‚ä½•ç†è§£è¿™äº›ç»“æœ:")
    print("  1ï¸âƒ£  KæŠ˜äº¤å‰éªŒè¯ç»“æœ (ä¸Šæ–¹è¡¨æ ¼):")
    print("     - ç”¨é€”: é€‰æ‹©æœ€ä½³æ¨¡å‹ã€è°ƒæ•´è¶…å‚æ•°ã€è¯„ä¼°æ¨¡å‹ç¨³å®šæ€§")
    print("     - æ•°æ®: train+val åˆå¹¶åKæŠ˜åˆ’åˆ†")
    print("  2ï¸âƒ£  æœ€ç»ˆæµ‹è¯•é›†ç»“æœ (æœ¬èŠ‚):")
    print("     - ç”¨é€”: æŠ¥å‘Šæ¨¡å‹çš„çœŸå®æ³›åŒ–èƒ½åŠ›")
    print("     - æ•°æ®: å®Œå…¨ç‹¬ç«‹çš„æµ‹è¯•é›†ï¼Œä»æœªå‚ä¸è®­ç»ƒ")
    print("     - ğŸ‘‰ åœ¨è®ºæ–‡ä¸­æŠ¥å‘Šè¿™ä¸ªç»“æœï¼")
    
    return all_results, summary, test_metrics


# ==========================================
# 7. ä¸»å…¥å£
# ==========================================
if __name__ == "__main__":
    all_results, summary, final_test_metrics = run_kfold_cross_validation()
    print("\nâœ… å®Œæ•´KæŠ˜äº¤å‰éªŒè¯æµç¨‹å®Œæˆï¼")
