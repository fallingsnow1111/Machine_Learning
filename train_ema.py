import sys
import os
from pathlib import Path
from typing import Any, Optional
import torch
from ultralytics import YOLO
import ultralytics.nn.tasks as tasks
# å¯¼å…¥ä½ çš„è‡ªå®šä¹‰æ¨¡å—
from custom_modules import ASPP, EMA

# --- æ ¸å¿ƒï¼šæ³¨å†Œè‡ªå®šä¹‰æ¨¡å— ---
def register_custom_layers():
    # ultralytics.nn.tasks é‡Œæ˜¯åŠ¨æ€æŸ¥æ‰¾æ¨¡å—ï¼Œè¿™é‡Œç”¨ setattr æ³¨å†Œ
    setattr(tasks, "ASPP", ASPP)
    setattr(tasks, "EMA", EMA)
    print("âœ… å·²æˆåŠŸæ³¨å†Œ ASPP å’Œ EMA æ¨¡å—")

def _find_project_root(start: Path) -> Path:
    """ä»è„šæœ¬ä½ç½®å‘ä¸Šæ‰¾é¡¹ç›®æ ¹ç›®å½•ï¼ˆåŒ…å« Data/ å’Œ ultralytics/ æˆ– *.yamlï¼‰ã€‚"""
    current = start
    for _ in range(10):
        if (current / "Data").exists() and ((current / "ultralytics").exists() or list(current.glob("*.yaml"))):
            return current
        if current.parent == current:
            break
        current = current.parent
    return start


def _pick_dataset_yaml(project_root: Path) -> Path:
    """ä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡ DATA_YAMLï¼Œå¦åˆ™ä»å¸¸è§ä½ç½®æŒ‘ä¸€ä¸ªå­˜åœ¨çš„ã€‚"""
    env_path = os.getenv("DATA_YAML")
    if env_path:
        return Path(env_path).expanduser().resolve()

    candidates = [
        project_root / "Data" / "Merged" / "no_noise11_processed" / "dataset.yaml",
        project_root / "Data" / "Merged" / "noise11_processed" / "dataset.yaml",
        project_root / "Data" / "Merged" / "no_noise11" / "dataset_merged.yaml",
        project_root / "Data" / "Merged" / "noise11" / "dataset_merged.yaml",
        project_root / "Data" / "dataset.yaml",
    ]
    for p in candidates:
        if p.exists():
            return p

    merged_dir = project_root / "Data" / "Merged"
    if merged_dir.exists():
        # å…œåº•ï¼šè‡ªåŠ¨é€‰ä¸€ä¸ªèƒ½æ‰¾åˆ°çš„ dataset*.yaml
        for p in merged_dir.rglob("dataset*.yaml"):
            return p.resolve()
    # é»˜è®¤è¿”å›ç¬¬ä¸€ä¸ªï¼Œåç»­ä¼šæŠ¥æ›´æ˜ç¡®çš„é”™
    return candidates[0]


# 1. è·¯å¾„å¤„ç†ï¼ˆæœ¬åœ°/Colab/Kaggle éƒ½å°½é‡ç¨³ï¼‰
script_dir = Path(__file__).resolve().parent
PROJECT_ROOT = _find_project_root(script_dir)
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

try:
    os.chdir(PROJECT_ROOT)
    print(f"ğŸ“ å·¥ä½œç›®å½•: {os.getcwd()}")
except Exception as e:
    print(f"âš ï¸ åˆ‡æ¢ç›®å½•å¤±è´¥: {e}")

# ==========================================
# 2. å¯¹é½ Baseline é…ç½®å‚æ•°
# ==========================================
# æ•°æ®é›†åœ°å€åœ¨è¿™é‡Œä¼ å…¥ï¼
DATA_YAML_PATH = _pick_dataset_yaml(PROJECT_ROOT)
TRAIN_DATA = str(DATA_YAML_PATH)
VAL_DATA = str(DATA_YAML_PATH)

# æŒ‡å‘ä½ é‚£ä¸ªå¸¦ ASPP/EMA/P2 çš„æ–° YAML
MODEL_CONFIG = str((PROJECT_ROOT / "yolo_ema.yaml").resolve())
PRETRAINED_WEIGHTS = str((PROJECT_ROOT / "pt" / "yolo11n.pt").resolve())
DEVICE = '0' if torch.cuda.is_available() else 'cpu'

def run_experiment():
    # å¿…é¡»åœ¨åˆå§‹åŒ– YOLO å‰æ³¨å†Œæ¨¡å—
    register_custom_layers()

    if not Path(TRAIN_DATA).exists():
        raise FileNotFoundError(
            "æ‰¾ä¸åˆ°æ•°æ®é›†é…ç½®æ–‡ä»¶(dataset.yaml)ã€‚\n"
            f"å½“å‰ TRAIN_DATA: {TRAIN_DATA}\n"
            "ä½ å¯ä»¥ï¼š\n"
            "1) æŠŠæ­£ç¡®çš„ dataset.yaml æ”¾åˆ°é¡¹ç›®å†…ï¼›æˆ–\n"
            "2) åœ¨è¿è¡Œå‰è®¾ç½®ç¯å¢ƒå˜é‡ DATA_YAML=/ç»å¯¹è·¯å¾„/åˆ°/dataset.yaml\n"
            "Kaggle ä¸Šä¹Ÿè¦ç¡®ä¿ images/train ä¸ images/val ç›®å½•çœŸå®å­˜åœ¨ã€‚"
        )

    if not Path(MODEL_CONFIG).exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ¨¡å‹ç»“æ„ YAML: {MODEL_CONFIG}")

    # --- ç¬¬ä¸€æ­¥ï¼šåŠ è½½æ–°ç»“æ„æ¨¡å‹ ---
    model = YOLO(MODEL_CONFIG)

    # å°è¯•åŠ è½½é¢„è®­ç»ƒæƒé‡ 
    # æ³¨æ„ï¼šå› ä¸ºä½ æ”¹äº†ç»“æ„ï¼ˆå¤šäº†P2å’ŒASPPï¼‰ï¼Œé¢„è®­ç»ƒæƒé‡åªèƒ½åŠ è½½éª¨å¹²ç½‘éƒ¨åˆ†ï¼Œè¿™æ˜¯æ­£å¸¸çš„
    try:
        model.load(PRETRAINED_WEIGHTS)
        print("âœ… æˆåŠŸåŠ è½½é¢„è®­ç»ƒæƒé‡ï¼ˆéƒ¨åˆ†åŒ¹é…ï¼‰")
    except Exception as e:
        print(f"âš ï¸ æƒé‡åŠ è½½æç¤º: {e}")

    # --- ç¬¬äºŒæ­¥ï¼šå¼€å§‹è®­ç»ƒ (å‚æ•°å®Œå…¨åŒæ­¥ Baseline) ---
    print("\nğŸš€ å¼€å§‹è®­ç»ƒé˜¶æ®µ...")
    results = model.train(
        data=TRAIN_DATA,
        epochs=50,
        imgsz=1024,      # æ³¨æ„ï¼šä½ ä¹‹å‰æåˆ°ç”¨1024ï¼Œå»ºè®®è¿™é‡Œæ”¹ä¸º1024ä»¥åŒ¹é…å°ç›®æ ‡éœ€æ±‚
        batch=16,        # å¦‚æœæ˜¾å­˜ä¸å¤Ÿï¼Œè¯·è°ƒå› 16
        patience=0, 
        optimizer='AdamW',
        lr0=0.0005,      # ä¿æŒä½ çš„ Baseline å‚æ•°
        lrf=0.01,
        warmup_epochs=5.0,
        translate=0.05,
        scale=0.1,
        copy_paste=0.4,
        device=DEVICE,
        plots=True,
        dropout=0.2,
    )

    # --- ç¬¬ä¸‰æ­¥ï¼šè‡ªåŠ¨éªŒè¯ ---
    print("\nğŸ” å¼€å§‹éªŒè¯é˜¶æ®µ...")
    save_dir: Optional[str] = getattr(results, "save_dir", None)
    if not save_dir:
        raise RuntimeError("è®­ç»ƒæœªè¿”å› save_dirï¼Œæ— æ³•å®šä½ best.pt")
    best_model_path = os.path.join(save_dir, 'weights', 'best.pt')
    best_model = YOLO(best_model_path)

    metrics = best_model.val(
        data=VAL_DATA,
        split="test", 
        imgsz=1024,     # éªŒè¯å°ºå¯¸ä¹Ÿè¦å’Œè®­ç»ƒä¿æŒä¸€è‡´
        batch=16,
        device=DEVICE
    )

    print(f"\næœ€ç»ˆæµ‹è¯•é›†ç»“æœ (mAP50): {metrics.box.map50:.4f}")

if __name__ == "__main__":
    run_experiment()