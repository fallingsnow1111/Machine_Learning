import torch
from torch import nn
import torch.nn.functional as F
from modelscope import AutoModel
import numpy as np
import os


class DINO3Preprocessor(nn.Module):
    """
    DINO3 Preprocessor - åœ¨P0è¾“å…¥é˜¶æ®µå¢å¼ºå›¾åƒ
    
    æ¶æ„: Input Image (3ch) -> æå– CLAHE é€šé“ -> DINO3ç‰¹å¾æå– -> å·ç§¯ç½‘ç»œ -> Enhanced Image (3ch)
    è¾“å‡ºå¢å¼ºçš„RGBå›¾åƒï¼Œè€Œéç‰¹å¾å‘é‡
    
    ğŸ”¥ ç‰¹åˆ«é€‚é…é¢„å¤„ç†ä¸‰é€šé“æ•°æ®ï¼š[Raw, Bilateral, CLAHE]
    - Channel 0: åŸå§‹ç°åº¦å›¾
    - Channel 1: åŒè¾¹æ»¤æ³¢å¢å¼º
    - Channel 2: CLAHE å¯¹æ¯”åº¦å¢å¼ºï¼ˆâ­ DINO ä¼šä½¿ç”¨è¿™ä¸ªé€šé“ï¼‰
    
    Args:
        c1: è¾“å…¥é€šé“æ•°ï¼ˆYOLO è‡ªåŠ¨ä¼ å…¥ï¼Œé€šå¸¸æ˜¯ 3ï¼‰
        output_channels: è¾“å‡ºé€šé“æ•°ï¼ˆé»˜è®¤ 3ï¼‰
        model_path: DINO æ¨¡å‹è·¯å¾„ï¼ˆå¯é€‰ï¼Œä¸ä¼ åˆ™è‡ªåŠ¨æ£€æµ‹ï¼‰
    """
    def __init__(self, c1, output_channels=3, model_path=None):
        super().__init__()
        self.c1 = c1
        self.output_channels = output_channels
        
        # ğŸ§  æ™ºèƒ½è·¯å¾„é€‰æ‹©ï¼šè‡ªåŠ¨æ£€æµ‹ Kaggle æˆ–æœ¬åœ°ç¯å¢ƒ
        if model_path is None:
            # 1. ä¼˜å…ˆä½¿ç”¨ç¡®åˆ‡çš„ Kaggle Model è·¯å¾„ï¼ˆåŒ…å«ç‰ˆæœ¬å·å’Œæ¡†æ¶åç§°ï¼‰
            absolute_path = '/kaggle/input/dinov3-vitl16/pytorch/default/1/dinov3-vitl16/facebook/dinov3-vitl16-pretrain-lvd1689m'
            
            if os.path.exists(absolute_path):
                self.model_path = absolute_path
                print("ğŸ¯ [P0] æˆåŠŸé”å®š Kaggle Model è·¯å¾„ï¼ˆå«ç‰ˆæœ¬å·ï¼‰")
            # 2. å¤‡é€‰ï¼šåŸæ¥çš„ç®€åŒ–è·¯å¾„
            elif os.path.exists('/kaggle/input/dinov3-vitl16/facebook/dinov3-vitl16'):
                self.model_path = '/kaggle/input/dinov3-vitl16/facebook/dinov3-vitl16'
                print("ğŸš€ [P0] ä½¿ç”¨å¤‡é€‰ Kaggle è·¯å¾„")
            # 3. å¤‡é€‰ï¼šæœ¬åœ°è·¯å¾„
            elif os.path.exists('./models/dinov3-vitl16'):
                self.model_path = './models/dinov3-vitl16'
                print("ğŸ’» [P0] æ£€æµ‹åˆ°æœ¬åœ°ç¯å¢ƒ")
            # 4. å…œåº•æ–¹æ¡ˆï¼šè‡ªåŠ¨æœç´¢ config.json
            else:
                import glob
                search_res = glob.glob('/kaggle/input/**/config.json', recursive=True)
                if search_res:
                    self.model_path = os.path.dirname(search_res[0])
                    print(f"ğŸ” [P0] è‡ªåŠ¨æœå¯»åˆ°è·¯å¾„: {self.model_path}")
                else:
                    # æœ€åå°è¯•åœ¨çº¿åŠ è½½
                    self.model_path = 'facebook/dinov3-vitl16-pretrain-lvd1689m'
                    print("ğŸŒ [P0] æœªæ‰¾åˆ°æœ¬åœ°æƒé‡ï¼Œå°è¯•åœ¨çº¿åŠ è½½")
        else:
            self.model_path = model_path
        
        # ä» modelscope åŠ è½½ DINO æ¨¡å‹
        print(f"ğŸ“¥ DINO3Preprocessor åŠ è½½è·¯å¾„: {self.model_path}")
        print(f"   è¾“å…¥é€šé“: {c1}, è¾“å‡ºé€šé“: {output_channels}")
        print(f"   ğŸ¯ ç­–ç•¥ï¼šæå– Channel 2 (CLAHE) -> Copy to RGB -> DINO")
        
        # âœ… ä¿®å¤ç‚¹ï¼šä½¿ç”¨ self.model_path è€Œä¸æ˜¯ model_name_or_path
        self.dino = AutoModel.from_pretrained(self.model_path, trust_remote_code=True)
        
        # å†»ç»“ DINO å‚æ•°
        for p in self.dino.parameters():
            p.requires_grad = False
        self.dino.eval()
        
        self.embed_dim = self.dino.config.hidden_size  # 1024 for vitl16
        self.patch_size = self.dino.config.patch_size  # 16
        
        # âš¡ æ˜¾å­˜ä¼˜åŒ–ï¼šé¢„æ³¨å†Œæ ‡å‡†åŒ–å‚æ•°ï¼ˆé˜²æ­¢ forward æ¯æ¬¡é‡å¤åˆ›å»ºï¼‰
        self.register_buffer("mean", torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1))
        self.register_buffer("std", torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1))
        
        # ç‰¹å¾å¤„ç†ç½‘ç»œ: DINOç‰¹å¾ -> 3é€šé“å¢å¼ºå›¾åƒ
        # å‚è€ƒä»“åº“: é€šè¿‡å·ç§¯ç½‘ç»œå°†é«˜ç»´ç‰¹å¾è½¬æ¢ä¸º3é€šé“å›¾åƒ
        self.feature_processor = nn.Sequential(
            nn.Conv2d(self.embed_dim, 512, 3, padding=1),
            nn.BatchNorm2d(512),
            nn.SiLU(inplace=True),
            nn.Conv2d(512, 256, 3, padding=1),
            nn.BatchNorm2d(256),
            nn.SiLU(inplace=True),
            nn.Conv2d(256, 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.SiLU(inplace=True),
            nn.Conv2d(64, self.output_channels, 3, padding=1),
            nn.Tanh()  # è¾“å‡ºå½’ä¸€åŒ–åˆ° [-1, 1]
        )
        
        # æ®‹å·®è¿æ¥æƒé‡
        self.gamma = nn.Parameter(torch.zeros(1))
        
        print(f"âœ… DINO3Preprocessor åˆå§‹åŒ–å®Œæˆ")
        print(f"   ç‰¹å¾ç»´åº¦: {self.embed_dim}, è¾“å‡ºé€šé“: {self.output_channels}")
    
    def forward(self, x):
        """
        Args:
            x: [B, 3, H, W] è¾“å…¥å›¾åƒ
               - Channel 0: åŸå§‹ç°åº¦å›¾
               - Channel 1: åŒè¾¹æ»¤æ³¢å¢å¼º
               - Channel 2: CLAHE å¯¹æ¯”åº¦å¢å¼º â­
        Returns:
            enhanced_image: [B, 3, H, W] å¢å¼ºåçš„å›¾åƒ
        """
        B, C, H, W = x.shape
        device = x.device
        original_input = x
        
        # ğŸ¯ å…³é”®æ”¹åŠ¨ï¼šåªæå– Channel 2 (CLAHE é€šé“)ï¼Œå®ƒå¯¹æ¯”åº¦æœ€å¼º
        if C >= 3:
            clahe_channel = x[:, 2:3, :, :]  # [B, 1, H, W] - CLAHE å¢å¼ºé€šé“
        else:
            # å¦‚æœæ˜¯å•é€šé“ï¼Œç›´æ¥ä½¿ç”¨
            clahe_channel = x[:, 0:1, :, :]
        
        # å¤åˆ¶æˆ 3 é€šé“çš„ä¼ª RGB å›¾ï¼ˆDINO æœŸæœ› RGB è¾“å…¥ï¼‰
        x_for_dino = clahe_channel.repeat(1, 3, 1, 1)  # [B, 3, H, W]
        
        # âš¡ æ˜¾å­˜ä¼˜åŒ–ï¼š518 æ˜¯ DINOv3 å®˜æ–¹æ¨èçš„å¹³è¡¡ç‚¹ï¼Œ1024 ä¼šæ¶ˆè€— 4 å€ä»¥ä¸Šæ˜¾å­˜
        # 518 æä¾› (518/14)^2 çº¦ 1369 ä¸ª tokensï¼Œè¶³ä»¥æ•æ‰ç»†å¾®ç‰¹å¾
        x_resized = F.interpolate(x_for_dino, size=(518, 518), mode='bilinear', align_corners=False)
        
        # ä½¿ç”¨é¢„æ³¨å†Œçš„æ ‡å‡†åŒ–å‚æ•°ï¼ˆä¸éœ€è¦æ¯æ¬¡åˆ›å»ºï¼‰
        x_normalized = (x_resized - self.mean) / self.std
        
        # æå– DINO ç‰¹å¾ï¼ˆğŸ›¡ï¸ å¼ºåˆ¶ä¸è®¡ç®—æ¢¯åº¦ï¼Œé˜²æ­¢ YOLO Trainer å¼ºè¡Œå¼€å¯æ¢¯åº¦ï¼‰
        with torch.no_grad():
            outputs = self.dino(pixel_values=x_normalized, output_hidden_states=True)
            # ç«‹åˆ» detach() åˆ‡æ–­è®¡ç®—å›¾ï¼Œè¿™æ˜¯æœ€åçš„é˜²çº¿
            last_hidden_state = outputs.hidden_states[-1].detach()  # [B, num_tokens, embed_dim]
        
        # å»æ‰ [CLS] token å’Œ register tokens
        num_registers = 4
        spatial_features = last_hidden_state[:, 1 + num_registers:, :]  # [B, num_patches, embed_dim]
        
        # é‡å¡‘ä¸ºç©ºé—´ç‰¹å¾å›¾
        _, num_patches, _ = spatial_features.shape
        h = w = int(np.sqrt(num_patches))
        dino_features = spatial_features.permute(0, 2, 1).reshape(B, self.embed_dim, h, w)
        
        # é€šè¿‡ç‰¹å¾å¤„ç†ç½‘ç»œè½¬æ¢ä¸º3é€šé“å›¾åƒ
        enhanced_features = self.feature_processor(dino_features)
        
        # ä¸Šé‡‡æ ·åˆ°åŸå§‹å°ºå¯¸
        enhanced_features = F.interpolate(
            enhanced_features, size=(H, W), mode='bilinear', align_corners=False
        )
        
        # Tanhè¾“å‡ºæ˜¯ [-1, 1]ï¼Œå½’ä¸€åŒ–åˆ° [0, 1]
        enhanced_features = (enhanced_features + 1) / 2
        
        # ä¸åŸå›¾åŠ æƒæ®‹å·®è¿æ¥
        enhanced_image = (
            original_input * (1 - self.gamma) + 
            enhanced_features * self.gamma
        )
        
        return enhanced_image


class DINO3Backbone(nn.Module):
    """
    DINO3 Backbone - åœ¨P3é˜¶æ®µå¢å¼ºCNNç‰¹å¾
    
    æ¶æ„: CNN Features -> æŠ•å½±ä¸ºä¼ªRGB -> DINO3ç‰¹å¾æå– -> ä¸åŸCNNç‰¹å¾èåˆ
    
    Args:
        c1: è¾“å…¥é€šé“æ•°ï¼ˆYOLO è‡ªåŠ¨ä¼ å…¥ï¼Œå¦‚ P3 å±‚çš„ 512 é€šé“ï¼‰
        output_channels: è¾“å‡ºé€šé“æ•°ï¼ˆå¦‚ 128ï¼‰
        model_path: DINO æ¨¡å‹è·¯å¾„ï¼ˆå¯é€‰ï¼Œä¸ä¼ åˆ™è‡ªåŠ¨æ£€æµ‹ï¼‰
    """
    def __init__(self, c1, output_channels=512, model_path=None):
        super().__init__()
        self.c1 = c1  # ä¿å­˜è¾“å…¥é€šé“æ•°
        self.output_channels = output_channels
        
        # ğŸ§  æ™ºèƒ½è·¯å¾„é€‰æ‹©ï¼šè‡ªåŠ¨æ£€æµ‹ Kaggle æˆ–æœ¬åœ°ç¯å¢ƒ
        if model_path is None:
            # 1. ä¼˜å…ˆä½¿ç”¨ç¡®åˆ‡çš„ Kaggle Model è·¯å¾„ï¼ˆå«ç‰ˆæœ¬å·ï¼‰
            # æ³¨æ„ï¼šP3 ä½¿ç”¨çš„æ˜¯ vits16 æˆ– vitl16ï¼Œæ ¹æ®ä½ çš„å®é™…æƒ…å†µè°ƒæ•´
            absolute_path = '/kaggle/input/dinov3-vitl16/pytorch/default/1/dinov3-vitl16/facebook/dinov3-vitl16-pretrain-lvd1689m'
            
            if os.path.exists(absolute_path):
                self.model_path = absolute_path
                print("ğŸ¯ [P3] æˆåŠŸé”å®š Kaggle Model è·¯å¾„ï¼ˆå«ç‰ˆæœ¬å·ï¼‰")
            # 2. å¤‡é€‰ï¼šç®€åŒ–è·¯å¾„
            elif os.path.exists('/kaggle/input/dinov3-vitl16/facebook/dinov3-vitl16'):
                self.model_path = '/kaggle/input/dinov3-vitl16/facebook/dinov3-vitl16'
                print("ğŸš€ [P3] ä½¿ç”¨å¤‡é€‰ Kaggle è·¯å¾„")
            # 3. å¤‡é€‰ï¼šæœ¬åœ°è·¯å¾„
            elif os.path.exists('./models/dinov3-vitl16'):
                self.model_path = './models/dinov3-vitl16'
                print("ğŸ’» [P3] æ£€æµ‹åˆ°æœ¬åœ°ç¯å¢ƒ")
            # 4. å…œåº•æ–¹æ¡ˆï¼šè‡ªåŠ¨æœç´¢
            else:
                import glob
                search_res = glob.glob('/kaggle/input/**/config.json', recursive=True)
                if search_res:
                    self.model_path = os.path.dirname(search_res[0])
                    print(f"ğŸ” [P3] è‡ªåŠ¨æœå¯»åˆ°è·¯å¾„: {self.model_path}")
                else:
                    self.model_path = 'facebook/dinov3-vitl16-pretrain-lvd1689m'
                    print("ğŸŒ [P3] æœªæ‰¾åˆ°æœ¬åœ°æƒé‡ï¼Œå°è¯•åœ¨çº¿åŠ è½½")
        else:
            self.model_path = model_path
        
        # ä» modelscope åŠ è½½ DINO æ¨¡å‹
        print(f"ğŸ“¥ DINO3Backbone åŠ è½½è·¯å¾„: {self.model_path}")
        print(f"   è¾“å…¥é€šé“: {c1}, è¾“å‡ºé€šé“: {output_channels}")
        
        # âœ… ä¿®å¤ç‚¹ï¼šä½¿ç”¨ self.model_path
        self.dino = AutoModel.from_pretrained(self.model_path, trust_remote_code=True)
        
        # å†»ç»“ DINO å‚æ•°
        for p in self.dino.parameters():
            p.requires_grad = False
        self.dino.eval()
        
        self.embed_dim = self.dino.config.hidden_size  # 1024 for vitl16
        self.patch_size = self.dino.config.patch_size  # 16

        
        # æŠ•å½±å±‚å°†åœ¨ç¬¬ä¸€æ¬¡forwardæ—¶åŠ¨æ€åˆ›å»ºï¼ˆå› ä¸ºinput_channelså¯èƒ½æœªçŸ¥ï¼‰
        self.input_projection = None
        self.fusion_layer = None
        self.feature_adapter = None
        self.spatial_projection = None
        
        print(f"âœ… DINO3Backbone åˆå§‹åŒ–å®Œæˆ")
        print(f"   ç‰¹å¾ç»´åº¦: {self.embed_dim}, è¾“å‡ºé€šé“: {self.output_channels}")
    
    def _create_projection_layers(self, input_channels=None):
        """æ ¹æ®å®é™…è¾“å…¥é€šé“æ•°åˆ›å»ºæŠ•å½±å±‚"""
        # å¦‚æœæ²¡æœ‰ä¼ å…¥ input_channelsï¼Œä½¿ç”¨ self.c1
        if input_channels is None:
            input_channels = self.c1
        
        # CNNç‰¹å¾ -> ä¼ªRGB (ç”¨äºé€å…¥DINO)
        self.input_projection = nn.Sequential(
            nn.Conv2d(input_channels, 64, 3, 1, 1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 3, 1, 1),
            nn.Tanh()
        )
        
        # DINOç‰¹å¾é€‚é…å™¨: embed_dim -> output_channels
        self.feature_adapter = nn.Sequential(
            nn.Linear(self.embed_dim, self.output_channels),
            nn.LayerNorm(self.output_channels),
            nn.GELU()
        )
        
        # ç©ºé—´æŠ•å½±: è°ƒæ•´ç‰¹å¾å›¾åˆ†è¾¨ç‡
        self.spatial_projection = nn.Sequential(
            nn.Conv2d(self.output_channels, self.output_channels, 3, 1, 1),
            nn.BatchNorm2d(self.output_channels),
            nn.ReLU(inplace=True)
        )
        
        # èåˆå±‚: CNNç‰¹å¾ + DINOç‰¹å¾
        self.fusion_layer = nn.Sequential(
            nn.Conv2d(input_channels + self.output_channels, self.output_channels, 3, 1, 1),
            nn.BatchNorm2d(self.output_channels),
            nn.ReLU(inplace=True)
        )
    
    def forward(self, x):
        """
        Args:
            x: [B, C, H, W] CNNç‰¹å¾ (å¦‚P3å±‚çš„256é€šé“ç‰¹å¾)
        Returns:
            enhanced_features: [B, output_channels, H, W] å¢å¼ºåçš„ç‰¹å¾
        """
        B, C, H, W = x.shape
        device = x.device
        
        # ç¬¬ä¸€æ¬¡forwardæ—¶åˆ›å»ºæŠ•å½±å±‚
        if self.input_projection is None:
            self.input_channels = C
            self._create_projection_layers(C)
            # ç§»åŠ¨åˆ°ä¸è¾“å…¥ç›¸åŒçš„è®¾å¤‡
            self.input_projection = self.input_projection.to(device)
            self.feature_adapter = self.feature_adapter.to(device)
            self.spatial_projection = self.spatial_projection.to(device)
            self.fusion_layer = self.fusion_layer.to(device)
        
        # 1. å°†CNNç‰¹å¾æŠ•å½±ä¸ºä¼ªRGBå›¾åƒ
        pseudo_rgb = self.input_projection(x)  # [B, 3, H, W]
        
        # 2. è°ƒæ•´åˆ°DINOæœŸæœ›çš„å°ºå¯¸
        dino_size = 224  # DINOè®­ç»ƒæ—¶çš„æ ‡å‡†å°ºå¯¸
        pseudo_rgb_resized = F.interpolate(
            pseudo_rgb, size=(dino_size, dino_size), 
            mode='bilinear', align_corners=False
        )
        
        # ImageNet å½’ä¸€åŒ–
        mean = torch.tensor([0.485, 0.456, 0.406], device=device).view(1, 3, 1, 1)
        std = torch.tensor([0.229, 0.224, 0.225], device=device).view(1, 3, 1, 1)
        pseudo_rgb_normalized = (pseudo_rgb_resized - mean) / std
        
        # 3. é€šè¿‡DINOæå–ç‰¹å¾ï¼ˆğŸ›¡ï¸ å¼ºåˆ¶ä¸è®¡ç®—æ¢¯åº¦ï¼‰
        with torch.no_grad():
            outputs = self.dino(pixel_values=pseudo_rgb_normalized, output_hidden_states=True)
            # ç«‹åˆ» detach() åˆ‡æ–­è®¡ç®—å›¾
            last_hidden_state = outputs.hidden_states[-1].detach()  # [B, num_tokens, embed_dim]
        
        # å»æ‰ [CLS] token å’Œ register tokens
        num_registers = 4
        spatial_features = last_hidden_state[:, 1 + num_registers:, :]  # [B, num_patches, embed_dim]
        
        # é‡å¡‘ä¸ºç©ºé—´ç‰¹å¾å›¾
        _, num_patches, _ = spatial_features.shape
        h = w = int(np.sqrt(num_patches))
        
        # 4. é€‚é…é€šé“ç»´åº¦
        # [B, num_patches, embed_dim] -> [B, h, w, embed_dim]
        features_2d = spatial_features.view(B, h, w, self.embed_dim)
        # é€šè¿‡çº¿æ€§å±‚é€‚é…: embed_dim -> output_channels
        adapted_features = self.feature_adapter(features_2d)  # [B, h, w, output_channels]
        # è½¬æ¢ä¸º [B, output_channels, h, w]
        adapted_features = adapted_features.permute(0, 3, 1, 2)
        
        # 5. ç©ºé—´æŠ•å½±å’Œä¸Šé‡‡æ ·åˆ°åŸå§‹å°ºå¯¸
        dino_features = self.spatial_projection(adapted_features)
        dino_features_resized = F.interpolate(
            dino_features, size=(H, W), 
            mode='bilinear', align_corners=False
        )
        
        # 6. ä¸åŸCNNç‰¹å¾èåˆ
        combined_features = torch.cat([x, dino_features_resized], dim=1)
        enhanced_features = self.fusion_layer(combined_features)
        
        return enhanced_features