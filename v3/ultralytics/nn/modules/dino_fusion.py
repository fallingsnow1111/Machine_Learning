import torch
from torch import nn
import torch.nn.functional as F
from modelscope import AutoModel
import numpy as np


class DINO3Preprocessor(nn.Module):
    """
    DINO3 Preprocessor - åœ¨P0è¾“å…¥é˜¶æ®µå¢å¼ºå›¾åƒ
    
    æ¶æ„: Input Image (3ch) -> DINO3ç‰¹å¾æå– -> å·ç§¯ç½‘ç»œ -> Enhanced Image (3ch)
    è¾“å‡ºå¢å¼ºçš„RGBå›¾åƒï¼Œè€Œéç‰¹å¾å‘é‡
    """
    def __init__(self, model_name='facebook/dinov3-vitl16-pretrain-lvd1689m', output_channels=3):
        super().__init__()
        self.model_name = model_name
        self.output_channels = output_channels
        
        # ä» modelscope åŠ è½½ DINO æ¨¡å‹
        print(f"ğŸ“¥ åŠ è½½ DINO æ¨¡å‹: {model_name}")
        self.dino = AutoModel.from_pretrained(model_name)
        self.embed_dim = self.dino.config.hidden_size  # 1024 for vitl16
        self.patch_size = self.dino.config.patch_size  # 16
        
        # å…³é”®ä¿®å¤ï¼šç¡®ä¿ DINO æ¨¡å‹è¾“å‡º hidden_states
        if hasattr(self.dino, 'config'):
            self.dino.config.output_hidden_states = True
        print(f"  âœ… å·²è®¾ç½® output_hidden_states = True")
        
        # ç‰¹å¾å¤„ç†ç½‘ç»œ: DINOç‰¹å¾ -> 3é€šé“å¢å¼ºå›¾åƒ
        # å‚è€ƒä»“åº“: é€šè¿‡å·ç§¯ç½‘ç»œå°†é«˜ç»´ç‰¹å¾è½¬æ¢ä¸º3é€šé“å›¾åƒ
        self.feature_processor = nn.Sequential(
            nn.Conv2d(self.embed_dim, 512, 3, padding=1),
            nn.BatchNorm2d(512),
            nn.SiLU(inplace=True),
            nn.Conv2d(512, 256, 3, padding=1),
            nn.BatchNorm2d(256),
            nn.SiLU(inplace=True),
            nn.Conv2d(256, 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.SiLU(inplace=True),
            nn.Conv2d(64, self.output_channels, 3, padding=1),
            nn.Tanh()  # è¾“å‡ºå½’ä¸€åŒ–åˆ° [-1, 1]
        )
        
        # æ®‹å·®è¿æ¥æƒé‡ï¼ˆåˆå§‹åŒ–ä¸º0.1ï¼Œè®©DINOå¢å¼ºæœ‰åˆå§‹ä½œç”¨ï¼‰
        self.gamma = nn.Parameter(torch.tensor([0.1]))
        
        print(f"âœ… DINO3Preprocessor åˆå§‹åŒ–å®Œæˆ")
        print(f"   ç‰¹å¾ç»´åº¦: {self.embed_dim}, è¾“å‡ºé€šé“: {self.output_channels}")
    
    def forward(self, x):
        """
        Args:
            x: [B, 3, H, W] è¾“å…¥å›¾åƒ
        Returns:
            enhanced_image: [B, 3, H, W] å¢å¼ºåçš„å›¾åƒ
        """
        B, C, H, W = x.shape
        device = x.device
        original_input = x
        
        # DINO æœŸæœ›è¾“å…¥: [B, 3, 1024, 1024]
        x_resized = F.interpolate(x, size=(1024, 1024), mode='bilinear', align_corners=False)
        mean = torch.tensor([0.485, 0.456, 0.406], device=x.device).view(1, 3, 1, 1)
        std = torch.tensor([0.229, 0.224, 0.225], device=x.device).view(1, 3, 1, 1)
        x_normalized = (x_resized - mean) / std
        
        # æå– DINO ç‰¹å¾
        with torch.no_grad():
            outputs = self.dino(pixel_values=x_normalized, output_hidden_states=True)
            # æ£€æŸ¥outputsæ˜¯å¦åŒ…å«hidden_states
            if hasattr(outputs, 'hidden_states') and outputs.hidden_states is not None:
                last_hidden_state = outputs.hidden_states[-4]  # [B, num_tokens, embed_dim] ä½¿ç”¨å€’æ•°ç¬¬4å±‚
            elif hasattr(outputs, 'last_hidden_state'):
                last_hidden_state = outputs.last_hidden_state
            else:
                # å¦‚æœéƒ½æ²¡æœ‰ï¼Œå°è¯•ç›´æ¥ä½¿ç”¨outputs
                raise RuntimeError(f"DINOæ¨¡å‹è¾“å‡ºæ ¼å¼é”™è¯¯: {type(outputs)}, å±æ€§: {dir(outputs)}")
        
        # å»æ‰ [CLS] token å’Œ register tokens
        num_registers = 4
        spatial_features = last_hidden_state[:, 1 + num_registers:, :]  # [B, num_patches, embed_dim]
        
        # é‡å¡‘ä¸ºç©ºé—´ç‰¹å¾å›¾
        _, num_patches, _ = spatial_features.shape
        h = w = int(np.sqrt(num_patches))
        dino_features = spatial_features.permute(0, 2, 1).reshape(B, self.embed_dim, h, w)
        
        # é€šè¿‡ç‰¹å¾å¤„ç†ç½‘ç»œè½¬æ¢ä¸º3é€šé“å›¾åƒ
        enhanced_features = self.feature_processor(dino_features)
        
        # ä¸Šé‡‡æ ·åˆ°åŸå§‹å°ºå¯¸
        enhanced_features = F.interpolate(
            enhanced_features, size=(H, W), mode='bilinear', align_corners=False
        )
        
        # Tanhè¾“å‡ºæ˜¯ [-1, 1]ï¼Œå½’ä¸€åŒ–åˆ° [0, 1]
        enhanced_features = (enhanced_features + 1) / 2
        
        # ä¸åŸå›¾åŠ æƒæ®‹å·®è¿æ¥
        enhanced_image = (
            original_input * (1 - self.gamma) + 
            enhanced_features * self.gamma
        )
        
        return enhanced_image


class DINO3Backbone(nn.Module):
    """
    DINO3 Backbone - åœ¨P3é˜¶æ®µå¢å¼ºCNNç‰¹å¾
    
    æ¶æ„: CNN Features -> æŠ•å½±ä¸ºä¼ªRGB -> DINO3ç‰¹å¾æå– -> ä¸åŸCNNç‰¹å¾èåˆ
    
    Args:
        model_name: DINOæ¨¡å‹åç§°
        input_channels_cnn: CNNç‰¹å¾çš„è¾“å…¥é€šé“æ•°ï¼ˆå¯é€‰ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨LazyConv2dè‡ªåŠ¨æ¨æ–­ï¼‰
        output_channels: æœ€ç»ˆè¾“å‡ºçš„ç‰¹å¾é€šé“æ•°
    """
    def __init__(self, model_name='facebook/dinov3-vits16-pretrain-lvd1689m', 
                 input_channels_cnn=None, output_channels=512):
        super().__init__()
        self.model_name = model_name
        self.input_channels_cnn = input_channels_cnn
        self.output_channels = output_channels
        
        # ä» modelscope åŠ è½½ DINO æ¨¡å‹
        print(f"ğŸ“¥ åŠ è½½ DINO æ¨¡å‹: {model_name}")
        self.dino = AutoModel.from_pretrained(model_name)
        self.embed_dim = self.dino.config.hidden_size  # DINOè¾“å‡ºçš„ç‰¹å¾ç»´åº¦ (1024 for vitl16)
        self.patch_size = self.dino.config.patch_size  # 16
        
        # å…³é”®ä¿®å¤ï¼šç¡®ä¿ DINO æ¨¡å‹è¾“å‡º hidden_states
        if hasattr(self.dino, 'config'):
            self.dino.config.output_hidden_states = True
        print(f"  âœ… å·²è®¾ç½® output_hidden_states = True")

        # CNNç‰¹å¾ -> ä¼ªRGBæŠ•å½±
        # å¦‚æœçŸ¥é“è¾“å…¥é€šé“æ•°ï¼Œä½¿ç”¨æ™®é€šConv2dï¼›å¦åˆ™ä½¿ç”¨LazyConv2d
        if input_channels_cnn is not None:
            self.input_projection = nn.Sequential(
                nn.Conv2d(input_channels_cnn, 64, 3, 1, 1),
                nn.BatchNorm2d(64),
                nn.ReLU(inplace=True),
                nn.Conv2d(64, 3, 1, 1),
                nn.Tanh()
            )
        else:
            self.input_projection = nn.Sequential(
                nn.LazyConv2d(64, 3, 1, 1),
                nn.BatchNorm2d(64),
                nn.ReLU(inplace=True),
                nn.Conv2d(64, 3, 1, 1),
                nn.Tanh()
            )
        
        # DINOç‰¹å¾é€‚é…å™¨: embed_dim -> output_channels
        self.feature_adapter = nn.Sequential(
            nn.Linear(self.embed_dim, self.output_channels),
            nn.LayerNorm(self.output_channels),
            nn.GELU()
        )
        
        # ç©ºé—´æŠ•å½±: è°ƒæ•´ç‰¹å¾å›¾åˆ†è¾¨ç‡
        self.spatial_projection = nn.Sequential(
            nn.Conv2d(self.output_channels, self.output_channels, 3, 1, 1),
            nn.BatchNorm2d(self.output_channels),
            nn.ReLU(inplace=True)
        )
        
        # èåˆå±‚: CNNç‰¹å¾ + DINOç‰¹å¾ -> output_channels
        # å¦‚æœçŸ¥é“è¾“å…¥é€šé“æ•°ï¼Œä½¿ç”¨æ™®é€šConv2dï¼›å¦åˆ™ä½¿ç”¨LazyConv2d
        if input_channels_cnn is not None:
            fusion_input_channels = input_channels_cnn + self.output_channels
            self.fusion_layer = nn.Sequential(
                nn.Conv2d(fusion_input_channels, self.output_channels, 3, 1, 1),
                nn.BatchNorm2d(self.output_channels),
                nn.ReLU(inplace=True)
            )
        else:
            self.fusion_layer = nn.Sequential(
                nn.LazyConv2d(self.output_channels, 3, 1, 1),
                nn.BatchNorm2d(self.output_channels),
                nn.ReLU(inplace=True)
            )
        
        print(f"âœ… DINO3Backbone åˆå§‹åŒ–å®Œæˆ")
        print(f"   DINOç‰¹å¾ç»´åº¦: {self.embed_dim}")
        print(f"   CNNè¾“å…¥é€šé“: {input_channels_cnn if input_channels_cnn else 'Auto'}")
        print(f"   æœ€ç»ˆè¾“å‡ºé€šé“: {self.output_channels}")
    
    def forward(self, x):
        """
        Args:
            x: [B, C, H, W] CNNç‰¹å¾ (å¦‚P3å±‚çš„256é€šé“ç‰¹å¾)
        Returns:
            enhanced_features: [B, output_channels, H, W] å¢å¼ºåçš„ç‰¹å¾
        """
        B, C, H, W = x.shape
        device = x.device
        
        # 1. å°†CNNç‰¹å¾æŠ•å½±ä¸ºä¼ªRGBå›¾åƒ
        pseudo_rgb = self.input_projection(x)  # [B, 3, H, W]
        
        # 2. è°ƒæ•´åˆ°DINOæœŸæœ›çš„å°ºå¯¸
        dino_size = 224  # DINOè®­ç»ƒæ—¶çš„æ ‡å‡†å°ºå¯¸
        pseudo_rgb_resized = F.interpolate(
            pseudo_rgb, size=(dino_size, dino_size), 
            mode='bilinear', align_corners=False
        )
        
        # ImageNet å½’ä¸€åŒ–
        mean = torch.tensor([0.485, 0.456, 0.406], device=device).view(1, 3, 1, 1)
        std = torch.tensor([0.229, 0.224, 0.225], device=device).view(1, 3, 1, 1)
        pseudo_rgb_normalized = (pseudo_rgb_resized - mean) / std
        
        # 3. é€šè¿‡DINOæå–ç‰¹å¾
        with torch.no_grad():
            outputs = self.dino(pixel_values=pseudo_rgb_normalized, output_hidden_states=True)
            # æ£€æŸ¥outputsæ˜¯å¦åŒ…å«hidden_states
            if hasattr(outputs, 'hidden_states') and outputs.hidden_states is not None:
                last_hidden_state = outputs.hidden_states[-4]  # [B, num_tokens, embed_dim] ä½¿ç”¨å€’æ•°ç¬¬4å±‚
            elif hasattr(outputs, 'last_hidden_state'):
                last_hidden_state = outputs.last_hidden_state
            else:
                # å¦‚æœéƒ½æ²¡æœ‰ï¼Œå°è¯•ç›´æ¥ä½¿ç”¨outputs
                raise RuntimeError(f"DINOæ¨¡å‹è¾“å‡ºæ ¼å¼é”™è¯¯: {type(outputs)}, å±æ€§: {dir(outputs)}")
        
        # å»æ‰ [CLS] token å’Œ register tokens
        num_registers = 4
        spatial_features = last_hidden_state[:, 1 + num_registers:, :]  # [B, num_patches, embed_dim]
        
        # é‡å¡‘ä¸ºç©ºé—´ç‰¹å¾å›¾
        _, num_patches, _ = spatial_features.shape
        h = w = int(np.sqrt(num_patches))
        
        # 4. é€‚é…é€šé“ç»´åº¦
        # [B, num_patches, embed_dim] -> [B, h, w, embed_dim]
        features_2d = spatial_features.view(B, h, w, self.embed_dim)
        # é€šè¿‡çº¿æ€§å±‚é€‚é…: embed_dim -> output_channels
        adapted_features = self.feature_adapter(features_2d)  # [B, h, w, output_channels]
        # è½¬æ¢ä¸º [B, output_channels, h, w]
        adapted_features = adapted_features.permute(0, 3, 1, 2)
        
        # 5. ç©ºé—´æŠ•å½±å’Œä¸Šé‡‡æ ·åˆ°åŸå§‹å°ºå¯¸
        dino_features = self.spatial_projection(adapted_features)
        dino_features_resized = F.interpolate(
            dino_features, size=(H, W), 
            mode='bilinear', align_corners=False
        )
        
        # 6. ä¸åŸCNNç‰¹å¾èåˆ
        combined_features = torch.cat([x, dino_features_resized], dim=1)
        enhanced_features = self.fusion_layer(combined_features)
        
        return enhanced_features