# DINOv3 åˆ° YOLO11 çŸ¥è¯†è’¸é¦è®­ç»ƒ

è¿™ä¸ªé¡¹ç›®ä½¿ç”¨ [lightly-train](https://github.com/lightly-ai/lightly-train) å°† DINOv3 çš„çŸ¥è¯†è’¸é¦åˆ° YOLO11 æ¨¡å‹ä¸­ã€‚

## ğŸ“‹ ç›®å½•

- [ç®€ä»‹](#ç®€ä»‹)
- [å®‰è£…](#å®‰è£…)
- [ä½¿ç”¨æ–¹æ³•](#ä½¿ç”¨æ–¹æ³•)
- [é…ç½®é€‰é¡¹](#é…ç½®é€‰é¡¹)
- [è®­ç»ƒæµç¨‹](#è®­ç»ƒæµç¨‹)
- [ç»“æœ](#ç»“æœ)

## ğŸ¯ ç®€ä»‹

çŸ¥è¯†è’¸é¦æ˜¯ä¸€ç§æ¨¡å‹å‹ç¼©æŠ€æœ¯ï¼Œé€šè¿‡è®©å°æ¨¡å‹ï¼ˆå­¦ç”Ÿï¼‰å­¦ä¹ å¤§æ¨¡å‹ï¼ˆæ•™å¸ˆï¼‰çš„çŸ¥è¯†ï¼Œä»è€Œæé«˜å°æ¨¡å‹çš„æ€§èƒ½ã€‚

**è®­ç»ƒæµç¨‹ï¼š**
1. **é˜¶æ®µ1 - è’¸é¦é¢„è®­ç»ƒ**ï¼šä½¿ç”¨ DINOv3 æ•™å¸ˆæ¨¡å‹åœ¨æ— æ ‡ç­¾æ•°æ®ä¸Šé¢„è®­ç»ƒ YOLO11 éª¨å¹²ç½‘ç»œ
2. **é˜¶æ®µ2 - ç›®æ ‡æ£€æµ‹å¾®è°ƒ**ï¼šåœ¨æ ‡æ³¨çš„æ£€æµ‹æ•°æ®ä¸Šå¾®è°ƒé¢„è®­ç»ƒçš„æ¨¡å‹

**ä¼˜åŠ¿ï¼š**
- ğŸš€ æå‡å°æ¨¡å‹æ€§èƒ½ï¼ˆåœ¨ COCO æ•°æ®é›†ä¸Šæå‡ 2-3% mAPï¼‰
- ğŸ“¦ ä¿æŒæ¨¡å‹ä½“ç§¯å°å·§ï¼Œé€‚åˆéƒ¨ç½²
- ğŸ’¡ å……åˆ†åˆ©ç”¨æ— æ ‡ç­¾æ•°æ®

## ğŸ“¦ å®‰è£…

### 1. å®‰è£… lightly-train

```bash
pip install lightly-train
```

### 2. å®‰è£…å…¶ä»–ä¾èµ–

```bash
pip install ultralytics torch torchvision
```

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### å¿«é€Ÿå¼€å§‹

```python
from Code.xie.light_train_v2 import DINOv3ToYOLO11Distillation

# åˆ›å»ºè®­ç»ƒå™¨
trainer = DINOv3ToYOLO11Distillation(
    data_dir="Data/Raw/dust",
    output_dir="runs/distillation",
)

# è¿è¡Œå®Œæ•´è®­ç»ƒæµç¨‹
trainer.run_full_pipeline(
    teacher_model="dinov3/vits16",      # DINOv3 æ•™å¸ˆæ¨¡å‹
    student_model="ultralytics/yolo11n", # YOLO11 å­¦ç”Ÿæ¨¡å‹
    distillation_epochs=100,             # è’¸é¦è½®æ•°
    finetune_epochs=50,                  # å¾®è°ƒè½®æ•°
    batch_size=16,
    image_size=640,
)
```

### åˆ†æ­¥è®­ç»ƒ

å¦‚æœä½ æƒ³åˆ†åˆ«æ§åˆ¶ä¸¤ä¸ªé˜¶æ®µï¼š

```python
from Code.xie.light_train_v2 import DINOv3ToYOLO11Distillation

trainer = DINOv3ToYOLO11Distillation(
    data_dir="Data/Raw/dust",
    output_dir="runs/distillation",
)

# é˜¶æ®µ1: è’¸é¦é¢„è®­ç»ƒ
pretrained_weights = trainer.stage1_distillation(
    teacher_model="dinov3/vits16",
    student_model="ultralytics/yolo11n",
    epochs=100,
    batch_size=32,
)

# é˜¶æ®µ2: å¾®è°ƒ
trainer.stage2_finetune(
    pretrained_weights=pretrained_weights,
    epochs=50,
    batch_size=16,
)

# éªŒè¯
trainer.validate()
```

### å‘½ä»¤è¡Œè¿è¡Œ

```bash
cd /home/xie/Others/Project/deeplearning/Machine_Learning
python Code/xie/light_train_v2.py
```

## âš™ï¸ é…ç½®é€‰é¡¹

### æ•™å¸ˆæ¨¡å‹é€‰é¡¹

DINOv3 æ¨¡å‹ï¼ˆæ¨èç”¨äºè’¸é¦ï¼‰ï¼š
- `dinov3/vits16` - Small (22M å‚æ•°) - å¿«é€Ÿè®­ç»ƒ
- `dinov3/vitb16` - Base (86M å‚æ•°) - å¹³è¡¡æ€§èƒ½å’Œé€Ÿåº¦
- `dinov3/vitl16` - Large (304M å‚æ•°) - æœ€ä½³æ€§èƒ½

### å­¦ç”Ÿæ¨¡å‹é€‰é¡¹

YOLO11 æ¨¡å‹ï¼š
- `ultralytics/yolo11n` - Nano (2.6M å‚æ•°) - æœ€å¿«é€Ÿåº¦
- `ultralytics/yolo11s` - Small (9.4M å‚æ•°) - å¹³è¡¡
- `ultralytics/yolo11m` - Medium (20.1M å‚æ•°) - æ›´é«˜ç²¾åº¦
- `ultralytics/yolo11l` - Large (25.3M å‚æ•°) - é«˜ç²¾åº¦
- `ultralytics/yolo11x` - Extra Large (56.9M å‚æ•°) - æœ€é«˜ç²¾åº¦

### è®­ç»ƒå‚æ•°

```python
trainer.run_full_pipeline(
    teacher_model="dinov3/vits16",       # æ•™å¸ˆæ¨¡å‹
    student_model="ultralytics/yolo11n", # å­¦ç”Ÿæ¨¡å‹
    distillation_epochs=100,              # è’¸é¦é¢„è®­ç»ƒè½®æ•° (å»ºè®® 100-300)
    finetune_epochs=50,                   # å¾®è°ƒè½®æ•° (å»ºè®® 50-100)
    batch_size=16,                        # æ‰¹é‡å¤§å° (æ ¹æ® GPU å†…å­˜è°ƒæ•´)
    image_size=640,                       # å›¾åƒå¤§å° (640/1280)
)
```

## ğŸ“Š è®­ç»ƒæµç¨‹è¯¦è§£

### é˜¶æ®µ1: è’¸é¦é¢„è®­ç»ƒ

**ç›®çš„**ï¼šåœ¨æ— æ ‡ç­¾å›¾åƒä¸Šå­¦ä¹ ç‰¹å¾è¡¨ç¤º

**è¾“å…¥**ï¼š
- æ— æ ‡ç­¾å›¾åƒ (Data/Raw/dust/images/train/)
- DINOv3 æ•™å¸ˆæ¨¡å‹

**è¾“å‡º**ï¼š
- é¢„è®­ç»ƒçš„ YOLO11 éª¨å¹²ç½‘ç»œ
- ä¿å­˜ä½ç½®: `runs/distillation/{experiment_name}/stage1_distillation/exported_models/exported_last.pt`

**è®­ç»ƒè¿‡ç¨‹**ï¼š
1. æ•™å¸ˆæ¨¡å‹ï¼ˆDINOv3ï¼‰æå–å›¾åƒç‰¹å¾
2. å­¦ç”Ÿæ¨¡å‹ï¼ˆYOLO11ï¼‰å­¦ä¹ æ¨¡ä»¿æ•™å¸ˆçš„ç‰¹å¾
3. ä½¿ç”¨è’¸é¦æŸå¤±ä¼˜åŒ–å­¦ç”Ÿæ¨¡å‹

### é˜¶æ®µ2: ç›®æ ‡æ£€æµ‹å¾®è°ƒ

**ç›®çš„**ï¼šåœ¨æ ‡æ³¨æ•°æ®ä¸Šè®­ç»ƒæ£€æµ‹å¤´

**è¾“å…¥**ï¼š
- æ ‡æ³¨çš„æ£€æµ‹æ•°æ® (Data/Raw/dust/)
- é¢„è®­ç»ƒçš„éª¨å¹²ç½‘ç»œ

**è¾“å‡º**ï¼š
- æœ€ç»ˆçš„æ£€æµ‹æ¨¡å‹
- ä¿å­˜ä½ç½®: `runs/distillation/{experiment_name}/stage2_finetune/train/weights/best.pt`

**è®­ç»ƒè¿‡ç¨‹**ï¼š
1. åŠ è½½é¢„è®­ç»ƒçš„éª¨å¹²ç½‘ç»œ
2. æ·»åŠ  YOLO æ£€æµ‹å¤´
3. åœ¨æ ‡æ³¨æ•°æ®ä¸Šå¾®è°ƒæ•´ä¸ªæ¨¡å‹
4. ä½¿ç”¨æ£€æµ‹æŸå¤±ï¼ˆåˆ†ç±» + å®šä½ + ç½®ä¿¡åº¦ï¼‰

## ğŸ“ˆ ç»“æœ

è®­ç»ƒå®Œæˆåï¼Œç»“æœä¿å­˜åœ¨ï¼š

```
runs/distillation/{experiment_name}/
â”œâ”€â”€ stage1_distillation/
â”‚   â”œâ”€â”€ checkpoints/
â”‚   â”‚   â””â”€â”€ last.ckpt
â”‚   â”œâ”€â”€ exported_models/
â”‚   â”‚   â””â”€â”€ exported_last.pt          # é¢„è®­ç»ƒæƒé‡
â”‚   â””â”€â”€ events.out.tfevents.*         # TensorBoard æ—¥å¿—
â””â”€â”€ stage2_finetune/
    â””â”€â”€ train/
        â”œâ”€â”€ weights/
        â”‚   â”œâ”€â”€ best.pt                # æœ€ä½³æ¨¡å‹
        â”‚   â””â”€â”€ last.pt                # æœ€åä¸€è½®æ¨¡å‹
        â”œâ”€â”€ results.png                # è®­ç»ƒæ›²çº¿
        â”œâ”€â”€ confusion_matrix.png       # æ··æ·†çŸ©é˜µ
        â””â”€â”€ val_batch*.jpg             # éªŒè¯å¯è§†åŒ–
```

### æŸ¥çœ‹è®­ç»ƒæ—¥å¿—

```bash
# TensorBoard (é˜¶æ®µ1)
tensorboard --logdir runs/distillation/{experiment_name}/stage1_distillation

# YOLO è®­ç»ƒæ—¥å¿— (é˜¶æ®µ2)
# æŸ¥çœ‹ runs/distillation/{experiment_name}/stage2_finetune/train/results.png
```

## ğŸ”§ å¸¸è§é—®é¢˜

### 1. å†…å­˜ä¸è¶³

å¦‚æœé‡åˆ° CUDA OOM é”™è¯¯ï¼Œå°è¯•ï¼š
- å‡å°‘ `batch_size` (ä¾‹å¦‚ä» 16 é™åˆ° 8)
- ä½¿ç”¨æ›´å°çš„æ•™å¸ˆæ¨¡å‹ (`dinov3/vits16`)
- å‡å°‘ `image_size` (ä¾‹å¦‚ä» 640 é™åˆ° 416)

### 2. è®­ç»ƒå¤ªæ…¢

- ä½¿ç”¨æ›´å°çš„æ•™å¸ˆæ¨¡å‹
- å‡å°‘ `distillation_epochs`
- å¢åŠ  `num_workers`

### 3. æ•ˆæœä¸å¥½

- å¢åŠ  `distillation_epochs` (å»ºè®®è‡³å°‘ 100 è½®)
- ä½¿ç”¨æ›´å¤§çš„æ•™å¸ˆæ¨¡å‹ (`dinov3/vitb16` æˆ– `vitl16`)
- ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ— æ ‡ç­¾æ•°æ® (å»ºè®® >= 10,000 å¼ å›¾åƒ)
- å¢åŠ  `finetune_epochs`

## ğŸ“š å‚è€ƒèµ„æ–™

- [lightly-train æ–‡æ¡£](https://docs.lightly.ai/train/)
- [lightly-train GitHub](https://github.com/lightly-ai/lightly-train)
- [DINOv3 è®ºæ–‡](https://arxiv.org/abs/2304.07193)
- [YOLO11 æ–‡æ¡£](https://docs.ultralytics.com/)

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æå‡ºé—®é¢˜å’Œæ”¹è¿›å»ºè®®ï¼

## ğŸ“„ è®¸å¯è¯

- lightly-train: Apache 2.0
- DINOv3: DINOv3 License
- Ultralytics YOLO: AGPL-3.0
