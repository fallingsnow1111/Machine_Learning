from pathlib import Path
import sys
import subprocess
import os
import shutil

# è‡ªåŠ¨å®‰è£…å¿…è¦çš„åŒ…
def install_package(package_name):
    """è‡ªåŠ¨å®‰è£…PythonåŒ…"""
    try:
        __import__(package_name.split('[')[0].replace('-', '_'))
        print(f"âœ“ {package_name} å·²å®‰è£…")
    except ImportError:
        print(f"æ­£åœ¨å®‰è£… {package_name}...")
        subprocess.check_call([sys.executable, "-m", "pip", "install", package_name])
        print(f"âœ“ {package_name} å®‰è£…å®Œæˆ")

# æ£€æŸ¥å¹¶å®‰è£…ä¾èµ–
print("æ£€æŸ¥ä¾èµ–åŒ…...")
required_packages = [
    'lightly-train',
    'torch',
    'torchvision', 
    'ultralytics',
    'timm',
    'pyyaml',
    'tqdm',
    'opencv-python',
    'matplotlib',
    'numpy'
]

for package in required_packages:
    install_package(package)

print("\næ‰€æœ‰ä¾èµ–å·²å‡†å¤‡å°±ç»ªï¼\n")

import cv2
import numpy as np
from tqdm import tqdm
import lightly_train
from ultralytics import YOLO
import torch

# ==================== å¢å¼ºé¢„å¤„ç†æ¨¡å— ====================
def process_image_channels_enhanced(img_path_str, target_size=(640, 640)):
    """
    å¢å¼ºç‰ˆå¤„ç†ï¼šæ›´æ¿€è¿›çš„å¯¹æ¯”åº¦å¢å¼º
    Ch0=ç›´æ–¹å›¾å‡è¡¡, Ch1=è‡ªé€‚åº”é˜ˆå€¼, Ch2=å¼ºCLAHE
    """
    img_gray = cv2.imread(img_path_str, 0)
    if img_gray is None:
        return None

    # 1. Lanczos æ’å€¼æ”¾å¤§
    img_upscaled = cv2.resize(img_gray, target_size, interpolation=cv2.INTER_LANCZOS4)

    # 2. æ„å»ºä¸‰ä¸ªé€šé“
    # Ch0: åŸå§‹æ”¾å¤§ + ç›´æ–¹å›¾å‡è¡¡åŒ–
    c0 = cv2.equalizeHist(img_upscaled)
    
    # Ch1: è‡ªé€‚åº”é˜ˆå€¼ï¼ˆçªå‡ºå°ç›®æ ‡è¾¹ç¼˜ï¼‰
    c1 = cv2.adaptiveThreshold(
        img_upscaled, 255, 
        cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
        cv2.THRESH_BINARY, 
        blockSize=11, 
        C=2
    )
    
    # Ch2: æ›´å¼ºçš„CLAHEï¼ˆå¢å¼ºå±€éƒ¨å¯¹æ¯”åº¦ï¼‰
    clahe = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(4, 4))
    c2 = clahe.apply(img_upscaled)

    # 3. åˆå¹¶
    merged_img = cv2.merge([c0, c1, c2])
    return merged_img

def preprocess_dataset(input_dir, output_dir, target_size=(640, 640), enhanced=True):
    """é¢„å¤„ç†æ•´ä¸ªæ•°æ®é›†"""
    input_path = Path(input_dir)
    output_path = Path(output_dir)
    
    if output_path.exists():
        print(f"æ¸…ç©ºç°æœ‰è¾“å‡ºç›®å½•: {output_path}")
        shutil.rmtree(output_path)
    output_path.mkdir(parents=True, exist_ok=True)

    files = [f for f in input_path.rglob('*') if f.is_file()]
    processed_count = 0

    print(f"\nå¼€å§‹é¢„å¤„ç†æ•°æ®é›†: {input_dir}")
    print(f"ç›®æ ‡å°ºå¯¸: {target_size}")
    print(f"å¢å¼ºæ¨¡å¼: {'å¯ç”¨' if enhanced else 'ç¦ç”¨'}")
    print(f"æ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶\n")
    
    process_func = process_image_channels_enhanced
    
    for file_path in tqdm(files, desc="é¢„å¤„ç†è¿›åº¦"):
        rel_path = file_path.relative_to(input_path)
        target_path = output_path / rel_path
        target_path.parent.mkdir(parents=True, exist_ok=True)

        if file_path.suffix.lower() in ['.jpg', '.jpeg', '.png', '.bmp', '.tif']:
            img = process_func(str(file_path), target_size)
            if img is not None:
                save_path = target_path.with_suffix('.png')
                cv2.imwrite(str(save_path), img, [cv2.IMWRITE_PNG_COMPRESSION, 3])
                processed_count += 1
        else:
            shutil.copy2(file_path, target_path)
    
    print(f"\né¢„å¤„ç†å®Œæˆï¼å…±å¤„ç† {processed_count} å¼ å›¾åƒ")
    return processed_count

def create_dataset_yaml(output_dir, classes=['dust']):
    """ç”Ÿæˆ dataset.yaml"""
    yaml_path = Path(output_dir) / 'dataset.yaml'
    with open(yaml_path, 'w') as f:
        f.write(f"path: {output_dir}\n")
        f.write("train: images/train\n")
        f.write("val: images/val\n")
        f.write("test: images/test\n\n")
        f.write(f"nc: {len(classes)}\n")
        f.write("names: " + str(classes) + "\n")
    print(f"âœ… å·²ç”Ÿæˆé…ç½®æ–‡ä»¶: {yaml_path}")
    return yaml_path

# ==================== ä¸»è®­ç»ƒæµç¨‹ ====================
if __name__ == "__main__":
    PROJECT_ROOT = Path(__file__).resolve().parent.parent.parent
    RAW_DATA_DIR = PROJECT_ROOT / "Data/Raw/dust"
    PROCESSED_DATA_DIR = PROJECT_ROOT / "Data/Processed/dust_640x640_enhanced"
    DISTILL_OUT_DIR = PROJECT_ROOT / "runs/distillation/dinov3_to_yolo11_640_stable"
    
    print("="*70)
    print("ğŸš€ ç¨³å®šè®­ç»ƒæµç¨‹ - é’ˆå¯¹æ³¢åŠ¨ä¼˜åŒ–")
    print("="*70)
    print(f"ğŸ“‚ åŸå§‹æ•°æ®: {RAW_DATA_DIR}")
    print(f"ğŸ“‚ å¤„ç†åæ•°æ®: {PROCESSED_DATA_DIR}")
    print(f"ğŸ“‚ è’¸é¦è¾“å‡º: {DISTILL_OUT_DIR}")
    print(f"ğŸ–¥ï¸  è®¾å¤‡: {'GPU (' + torch.cuda.get_device_name(0) + ')' if torch.cuda.is_available() else 'CPU'}")
    print("="*70 + "\n")
    
    # ==================== æ­¥éª¤ 1: å¢å¼ºé¢„å¤„ç† ====================
    print("\n" + "="*70)
    print("æ­¥éª¤ 1/4: å¢å¼ºé¢„å¤„ç†")
    print("="*70)
    
    processed_count = preprocess_dataset(
        input_dir=str(RAW_DATA_DIR),
        output_dir=str(PROCESSED_DATA_DIR),
        target_size=(640, 640),
        enhanced=True
    )
    
    if processed_count == 0:
        print("âŒ é¢„å¤„ç†å¤±è´¥ï¼Œæ²¡æœ‰å¤„ç†ä»»ä½•å›¾åƒï¼")
        sys.exit(1)
    
    DATASET_YAML = create_dataset_yaml(PROCESSED_DATA_DIR)
    
    # ==================== æ­¥éª¤ 2: çŸ¥è¯†è’¸é¦ ====================
    print("\n" + "="*70)
    print("æ­¥éª¤ 2/4: DINO v3 çŸ¥è¯†è’¸é¦")
    print("="*70)
    
    try:
        lightly_train.pretrain(
            out=str(DISTILL_OUT_DIR),
            data=str(PROCESSED_DATA_DIR),
            model="ultralytics/yolo11n",
            method="distillation",
            method_args={
                "teacher": "dinov3/vitl16",
            },
            epochs=100,  # å¢åŠ è’¸é¦è½®æ¬¡ä»¥è·å¾—æ›´å¥½çš„åˆå§‹åŒ–
            batch_size=16,  # å¢å¤§batchæé«˜ç¨³å®šæ€§
        )
        print("\nâœ… è’¸é¦å®Œæˆï¼")
    except Exception as e:
        print(f"\nâŒ è’¸é¦å¤±è´¥: {e}")
        print("ç»§ç»­ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹...")
        DISTILL_OUT_DIR = None
    
    # ==================== æ­¥éª¤ 3: åŠ è½½æ¨¡å‹ ====================
    print("\n" + "="*70)
    print("æ­¥éª¤ 3/4: åŠ è½½æ¨¡å‹")
    print("="*70)
    
    if DISTILL_OUT_DIR and (DISTILL_OUT_DIR / "exported_models/exported_last.pt").exists():
        exported_model_path = DISTILL_OUT_DIR / "exported_models/exported_last.pt"
        print(f"âœ… ä½¿ç”¨è’¸é¦æ¨¡å‹: {exported_model_path}")
        model = YOLO(str(exported_model_path))
    else:
        print("âš ï¸ ä½¿ç”¨å®˜æ–¹é¢„è®­ç»ƒæ¨¡å‹ YOLO11n")
        model = YOLO('yolo11n.pt')
    
    # ==================== æ­¥éª¤ 4: ç¨³å®šå¾®è°ƒè®­ç»ƒ ====================
    print("\n" + "="*70)
    print("æ­¥éª¤ 4/4: ç¨³å®šå¾®è°ƒè®­ç»ƒï¼ˆé™ä½æ³¢åŠ¨ï¼‰")
    print("="*70)
    
    results = model.train(
        data=str(DATASET_YAML),
        
        # ===== è®­ç»ƒè½®æ¬¡ =====
        epochs=300,  # é€‚ä¸­çš„è½®æ¬¡
        
        # ===== å›¾åƒå°ºå¯¸ =====
        imgsz=640,
        batch=32,  # æ›´å¤§çš„batchæé«˜ç¨³å®šæ€§ï¼ˆå¦‚æœæ˜¾å­˜å…è®¸ï¼‰
        device='0' if torch.cuda.is_available() else 'cpu',
        workers=8,
        
        # ===== å­¦ä¹ ç‡ç­–ç•¥ï¼ˆå…³é”®ï¼šé™ä½å­¦ä¹ ç‡ï¼‰=====
        lr0=0.001,      # ğŸ”¥ é™ä½åˆå§‹å­¦ä¹ ç‡ï¼ˆä»0.01é™åˆ°0.001ï¼‰
        lrf=0.01,       # ğŸ”¥ æé«˜æœ€ç»ˆå­¦ä¹ ç‡å æ¯”ï¼ˆä¿æŒç¨³å®šï¼‰
        warmup_epochs=5,  # å‡å°‘warmup
        warmup_momentum=0.8,
        warmup_bias_lr=0.1,
        
        # ===== ä¼˜åŒ–å™¨ï¼ˆä½¿ç”¨AdamWæé«˜ç¨³å®šæ€§ï¼‰=====
        optimizer='AdamW',  # ğŸ”¥ æ”¹ç”¨AdamWï¼ˆæ¯”SGDæ›´ç¨³å®šï¼‰
        momentum=0.937,
        weight_decay=0.0005,
        
        # ===== æ•°æ®å¢å¼ºï¼ˆé™ä½å¼ºåº¦ï¼‰=====
        hsv_h=0.0,
        hsv_s=0.0,
        hsv_v=0.2,     # ğŸ”¥ é™ä½äº®åº¦å¢å¼ºï¼ˆä»0.4é™åˆ°0.2ï¼‰
        degrees=10,    # ğŸ”¥ é™ä½æ—‹è½¬ï¼ˆä»20é™åˆ°10ï¼‰
        translate=0.1, # ğŸ”¥ é™ä½å¹³ç§»ï¼ˆä»0.2é™åˆ°0.1ï¼‰
        scale=0.3,     # ğŸ”¥ é™ä½ç¼©æ”¾ï¼ˆä»0.5é™åˆ°0.3ï¼‰
        shear=0.0,
        perspective=0.0,
        flipud=0.5,
        fliplr=0.5,
        
        # ===== Mosaic & Mixupï¼ˆé™ä½å¼ºåº¦ï¼‰=====
        mosaic=0.8,    # ğŸ”¥ é™ä½mosaicï¼ˆä»1.0é™åˆ°0.8ï¼‰
        mixup=0.05,    # ğŸ”¥ é™ä½mixupï¼ˆä»0.15é™åˆ°0.05ï¼‰
        copy_paste=0.1,  # ğŸ”¥ é™ä½copy-pasteï¼ˆä»0.3é™åˆ°0.1ï¼‰
        
        # ===== å…³é—­mosaicæ—¶æœº =====
        close_mosaic=50,  # ğŸ”¥ æå‰å…³é—­mosaicï¼ˆæœ€å50è½®ï¼‰
        
        # ===== æŸå¤±æƒé‡ï¼ˆå¹³è¡¡è°ƒæ•´ï¼‰=====
        box=7.5,      # ğŸ”¥ é€‚ä¸­çš„boxæƒé‡ï¼ˆä»10.0é™åˆ°7.5ï¼‰
        cls=0.5,      # ğŸ”¥ æé«˜åˆ†ç±»æƒé‡ï¼ˆä»0.3åˆ°0.5ï¼‰
        dfl=1.5,      # DFLæŸå¤±
        
        # ===== IoUè®¾ç½® =====
        iou=0.6,      # ğŸ”¥ æé«˜IoUé˜ˆå€¼ï¼ˆä»0.5åˆ°0.6ï¼‰
        
        # ===== NMSè®¾ç½® =====
        conf=0.001,
        
        # ===== ä¿å­˜è®¾ç½® =====
        project=str(PROJECT_ROOT / "runs/detect"),
        name="yolo11_dust_stable_distilled",
        patience=50,  # ğŸ”¥ é™ä½è€å¿ƒå€¼ï¼ˆä»100åˆ°50ï¼‰
        save=True,
        save_period=10,  # ğŸ”¥ æ›´é¢‘ç¹ä¿å­˜ï¼ˆä»20åˆ°10ï¼‰
        plots=True,
        val=True,
        
        # ===== å…¶ä»–ä¼˜åŒ– =====
        amp=True,
        fraction=1.0,
        
        # ===== éªŒè¯é¢‘ç‡ =====
        # å¢åŠ éªŒè¯é¢‘ç‡ä»¥æ›´å¥½ç›‘æ§
        val_period=1,  # æ¯è½®éªŒè¯
        
        # ===== Dropoutï¼ˆå¦‚æœæ”¯æŒï¼‰=====
        dropout=0.0,  # ä¸ä½¿ç”¨dropout

    )
    
    # ==================== æ­¥éª¤ 5: å¤šé˜ˆå€¼è¯„ä¼° ====================
    print("\n" + "="*70)
    print("æœ€ç»ˆè¯„ä¼°ï¼ˆå¤šç½®ä¿¡åº¦é˜ˆå€¼ï¼‰")
    print("="*70)
    
    best_model_path = results.save_dir / "weights/best.pt"
    best_model = YOLO(str(best_model_path))
    
    # æµ‹è¯•å¤šä¸ªç½®ä¿¡åº¦é˜ˆå€¼
    conf_thresholds = [0.001, 0.005, 0.01, 0.05, 0.1, 0.2]
    
    print("\nä¸åŒç½®ä¿¡åº¦é˜ˆå€¼çš„æ€§èƒ½ï¼š")
    print("-" * 60)
    best_conf = 0.001
    best_map50 = 0
    
    for conf_th in conf_thresholds:
        val_results = best_model.val(
            data=str(DATASET_YAML),
            split='test',
            imgsz=640,
            batch=32,
            device='0' if torch.cuda.is_available() else 'cpu',
            conf=conf_th,
            iou=0.5,
            max_det=300,
            plots=False,
        )
        
        map50 = val_results.box.map50
        precision = val_results.box.mp
        recall = val_results.box.mr
        
        print(f"Conf={conf_th:.3f} | mAP50={map50:.4f} | P={precision:.4f} | R={recall:.4f}")
        
        if map50 > best_map50:
            best_map50 = map50
            best_conf = conf_th
    
    print("-" * 60)
    print(f"âœ… æœ€ä½³ç½®ä¿¡åº¦é˜ˆå€¼: {best_conf:.3f} (mAP50={best_map50:.4f})")
    
    # ä½¿ç”¨æœ€ä½³é˜ˆå€¼é‡æ–°è¯„ä¼°å¹¶ä¿å­˜å¯è§†åŒ–
    print(f"\nä½¿ç”¨æœ€ä½³é˜ˆå€¼ {best_conf:.3f} ç”Ÿæˆå¯è§†åŒ–ç»“æœ...")
    val_results = best_model.val(
        data=str(DATASET_YAML),
        split='test',
        imgsz=640,
        batch=32,
        device='0' if torch.cuda.is_available() else 'cpu',
        conf=best_conf,
        iou=0.5,
        max_det=300,
        plots=True,
        save_json=True,
    )
    
    print("\n" + "="*70)
    print(f"ğŸ“Š æœ€ç»ˆæµ‹è¯•ç»“æœ (conf={best_conf:.3f})")
    print("="*70)
    print(f"mAP50:      {val_results.box.map50:.4f}")
    print(f"mAP50-95:   {val_results.box.map:.4f}")
    print(f"Precision:  {val_results.box.mp:.4f}")
    print(f"Recall:     {val_results.box.mr:.4f}")
    print("="*70)
    print(f"âœ… æœ€ä½³æ¨¡å‹: {best_model_path}")
    print(f"âœ… å¤„ç†åæ•°æ®: {PROCESSED_DATA_DIR}")
    print(f"âœ… æ¨èç½®ä¿¡åº¦: {best_conf:.3f}")
    print("="*70)