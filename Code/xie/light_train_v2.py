from pathlib import Path
import sys
import subprocess
import os
import shutil

# è‡ªåŠ¨å®‰è£…å¿…è¦çš„åŒ…
def install_package(package_name):
    """è‡ªåŠ¨å®‰è£…PythonåŒ…"""
    try:
        __import__(package_name.split('[')[0].replace('-', '_'))
        print(f"âœ“ {package_name} å·²å®‰è£…")
    except ImportError:
        print(f"æ­£åœ¨å®‰è£… {package_name}...")
        subprocess.check_call([sys.executable, "-m", "pip", "install", package_name])
        print(f"âœ“ {package_name} å®‰è£…å®Œæˆ")

# æ£€æŸ¥å¹¶å®‰è£…ä¾èµ–
print("æ£€æŸ¥ä¾èµ–åŒ…...")
required_packages = [
    'lightly-train',
    'torch',
    'torchvision', 
    'ultralytics',
    'timm',
    'pyyaml',
    'tqdm',
    'opencv-python',
    'matplotlib',
    'numpy'
]

for package in required_packages:
    install_package(package)

print("\næ‰€æœ‰ä¾èµ–å·²å‡†å¤‡å°±ç»ªï¼\n")

import cv2
import numpy as np
from tqdm import tqdm
import lightly_train
from ultralytics import YOLO
import torch

# ==================== å¢å¼ºé¢„å¤„ç†æ¨¡å— ====================
def process_image_channels_enhanced(img_path_str, target_size=(640, 640)):

    img_gray = cv2.imread(img_path_str, 0)
    if img_gray is None:
        return None

    # 1. Lanczos æ’å€¼æ”¾å¤§
    img_upscaled = cv2.resize(img_gray, target_size, interpolation=cv2.INTER_LANCZOS4)

    # 2. æ„å»ºä¸‰ä¸ªé€šé“
    # Ch0: åŸå§‹æ”¾å¤§ + ç›´æ–¹å›¾å‡è¡¡åŒ–
    c0 = cv2.equalizeHist(img_upscaled)
    
    # Ch1: è‡ªé€‚åº”é˜ˆå€¼ï¼ˆçªå‡ºå°ç›®æ ‡è¾¹ç¼˜ï¼‰
    c1 = cv2.adaptiveThreshold(
        img_upscaled, 255, 
        cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
        cv2.THRESH_BINARY, 
        blockSize=11, 
        C=2
    )
    
    # Ch2: æ›´å¼ºçš„CLAHEï¼ˆå¢å¼ºå±€éƒ¨å¯¹æ¯”åº¦ï¼‰
    clahe = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(4, 4))  # å¢åŠ clipLimitï¼Œå‡å°tileSize
    c2 = clahe.apply(img_upscaled)

    # 3. åˆå¹¶
    merged_img = cv2.merge([c0, c1, c2])
    return merged_img

def preprocess_dataset(input_dir, output_dir, target_size=(640, 640), enhanced=True):
    """é¢„å¤„ç†æ•´ä¸ªæ•°æ®é›†"""
    input_path = Path(input_dir)
    output_path = Path(output_dir)
    
    if output_path.exists():
        print(f"æ¸…ç©ºç°æœ‰è¾“å‡ºç›®å½•: {output_path}")
        shutil.rmtree(output_path)
    output_path.mkdir(parents=True, exist_ok=True)

    files = [f for f in input_path.rglob('*') if f.is_file()]
    processed_count = 0

    print(f"\nå¼€å§‹é¢„å¤„ç†æ•°æ®é›†: {input_dir}")
    print(f"ç›®æ ‡å°ºå¯¸: {target_size}")
    print(f"å¢å¼ºæ¨¡å¼: {'å¯ç”¨' if enhanced else 'ç¦ç”¨'}")
    print(f"æ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶\n")
    
    process_func = process_image_channels_enhanced if enhanced else process_image_channels
    
    for file_path in tqdm(files, desc="é¢„å¤„ç†è¿›åº¦"):
        rel_path = file_path.relative_to(input_path)
        target_path = output_path / rel_path
        target_path.parent.mkdir(parents=True, exist_ok=True)

        if file_path.suffix.lower() in ['.jpg', '.jpeg', '.png', '.bmp', '.tif']:
            img = process_func(str(file_path), target_size)
            if img is not None:
                save_path = target_path.with_suffix('.png')
                cv2.imwrite(str(save_path), img, [cv2.IMWRITE_PNG_COMPRESSION, 3])
                processed_count += 1
        else:
            shutil.copy2(file_path, target_path)
    
    print(f"\né¢„å¤„ç†å®Œæˆï¼å…±å¤„ç† {processed_count} å¼ å›¾åƒ")
    return processed_count

def create_dataset_yaml(output_dir, classes=['dust']):
    """ç”Ÿæˆ dataset.yaml"""
    yaml_path = Path(output_dir) / 'dataset.yaml'
    with open(yaml_path, 'w') as f:
        f.write(f"path: {output_dir}\n")
        f.write("train: images/train\n")
        f.write("val: images/val\n")
        f.write("test: images/test\n\n")
        f.write(f"nc: {len(classes)}\n")
        f.write("names: " + str(classes) + "\n")
    print(f"âœ… å·²ç”Ÿæˆé…ç½®æ–‡ä»¶: {yaml_path}")
    return yaml_path

# ==================== ä¸»è®­ç»ƒæµç¨‹ ====================
if __name__ == "__main__":
    # è®¾ç½®é¡¹ç›®æ ¹ç›®å½•
    PROJECT_ROOT = Path(__file__).resolve().parent.parent.parent
    
    # åŸå§‹æ•°æ®è·¯å¾„ï¼ˆ64Ã—64ç°åº¦å›¾ï¼‰
    RAW_DATA_DIR = PROJECT_ROOT / "Data/Raw/dust"
    
    # é¢„å¤„ç†åæ•°æ®è·¯å¾„ï¼ˆ640Ã—640ä¸‰é€šé“å›¾ï¼‰
    PROCESSED_DATA_DIR = PROJECT_ROOT / "Data/Processed/dust_640x640_enhanced"
    
    # è’¸é¦è¾“å‡ºè·¯å¾„
    DISTILL_OUT_DIR = PROJECT_ROOT / "runs/distillation/dinov3_to_yolo11_640_v2"
    
    # ==================== æ­¥éª¤ 1: å¢å¼ºé¢„å¤„ç† ====================
    print("\n" + "="*70)
    print("æ­¥éª¤ 1/4: å¢å¼ºé¢„å¤„ç† (æ›´å¼ºçš„å¯¹æ¯”åº¦å¢å¼º)")
    print("="*70)
    
    processed_count = preprocess_dataset(
        input_dir=str(RAW_DATA_DIR),
        output_dir=str(PROCESSED_DATA_DIR),
        target_size=(640, 640),
        enhanced=True  # å¯ç”¨å¢å¼ºæ¨¡å¼
    )
    
    if processed_count == 0:
        print("âŒ é¢„å¤„ç†å¤±è´¥ï¼Œæ²¡æœ‰å¤„ç†ä»»ä½•å›¾åƒï¼")
        sys.exit(1)
    
    # ç”Ÿæˆ dataset.yaml
    DATASET_YAML = create_dataset_yaml(PROCESSED_DATA_DIR)
    
    # ==================== æ­¥éª¤ 2: çŸ¥è¯†è’¸é¦ ====================
    print("\n" + "="*70)
    print("æ­¥éª¤ 2/4: çŸ¥è¯†è’¸é¦")
    print("="*70)
    
    SKIP_DISTILLATION = False  # è®¾ä¸º False å¯ç”¨è’¸é¦
    
    if not SKIP_DISTILLATION:
        try:
            lightly_train.pretrain(
                out=str(DISTILL_OUT_DIR),
                data=str(PROCESSED_DATA_DIR),
                model="ultralytics/yolo11n",
                method="distillation",
                method_args={
                    "teacher": "dinov3/vitl16",
                },
                epochs=100,  # å‡å°‘è’¸é¦è½®æ¬¡ï¼Œæ›´å¤šæ—¶é—´ç”¨äºå¾®è°ƒ
                batch_size=16,
            )
            print("\nâœ… è’¸é¦å®Œæˆï¼")
        except Exception as e:
            print(f"\nâŒ è’¸é¦å¤±è´¥: {e}")
            DISTILL_OUT_DIR = None
    else:
        print("âš ï¸ è·³è¿‡è’¸é¦æ­¥éª¤ï¼Œç›´æ¥ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹")
        DISTILL_OUT_DIR = None
    
    # ==================== æ­¥éª¤ 3: åŠ è½½æ¨¡å‹ ====================
    print("\n" + "="*70)
    print("æ­¥éª¤ 3/4: åŠ è½½æ¨¡å‹")
    print("="*70)
    
    if DISTILL_OUT_DIR and (DISTILL_OUT_DIR / "exported_models/exported_last.pt").exists():
        exported_model_path = DISTILL_OUT_DIR / "exported_models/exported_last.pt"
        print(f"âœ… ä½¿ç”¨è’¸é¦æ¨¡å‹: {exported_model_path}")
        model = YOLO(str(exported_model_path))
    else:
        model = YOLO('yolo11n.pt')
    
    # ==================== æ­¥éª¤ 4: ä¼˜åŒ–çš„å¾®è°ƒè®­ç»ƒ ====================
    print("\n" + "="*70)
    print("æ­¥éª¤ 4/4: ä¼˜åŒ–å¾®è°ƒï¼ˆé’ˆå¯¹å°ç›®æ ‡&ç°å°˜æ£€æµ‹ï¼‰")
    print("="*70)
    
    results = model.train(
        data=str(DATASET_YAML),
        
        # ===== è®­ç»ƒè½®æ¬¡ =====
        epochs=500,  # å¢åŠ è®­ç»ƒè½®æ¬¡
        
        # ===== å›¾åƒå°ºå¯¸ =====
        imgsz=640,
        batch=16,
        device='0' if torch.cuda.is_available() else 'cpu',
        workers=8,  # å¢åŠ æ•°æ®åŠ è½½çº¿ç¨‹
        
        # ===== å­¦ä¹ ç‡ç­–ç•¥=====
        lr0=0.001,      # æé«˜åˆå§‹å­¦ä¹ ç‡
        lrf=0.01,    # é™ä½æœ€ç»ˆå­¦ä¹ ç‡
        warmup_epochs=10,
        warmup_momentum=0.8,
        warmup_bias_lr=0.1,
        
        # ===== ä¼˜åŒ–å™¨ =====
        optimizer='AdamW', 
        momentum=0.937,
        weight_decay=0.0005,
        
        # ===== æ•°æ®å¢å¼º=====
        hsv_h=0.0,
        hsv_s=0.0,
        hsv_v=0.2,     # å¢åŠ äº®åº¦å¢å¼º
        degrees=10,    # å¢åŠ æ—‹è½¬
        translate=0.2, # å¢åŠ å¹³ç§»
        scale=0.5,     # å¢åŠ ç¼©æ”¾
        shear=0.0,
        perspective=0.0,
        flipud=0.5,
        fliplr=0.5,
        
        # ===== Mosaic & Mixup=====
        mosaic=1.0,    # å…¨ç¨‹ä½¿ç”¨mosaic
        mixup=0.15,    # å¢åŠ mixup
        copy_paste=0.3,  # å¯ç”¨copy-pasteå¢å¼º
        
        # ===== å…³é—­mosaicæ—¶æœº =====
        close_mosaic=0,  # ä¸æå‰å…³é—­mosaic
        
        # ===== æŸå¤±æƒé‡=====
        box=10.0,      # å¤§å¹…å¢åŠ boxæŸå¤±æƒé‡
        cls=0.3,       # é™ä½åˆ†ç±»æŸå¤±ï¼ˆå•ç±»ï¼‰
        dfl=2.0,       # å¢åŠ DFLæŸå¤±
        
        # ===== IoUè®¾ç½® =====
        iou=0.5,       # é™ä½IoUé˜ˆå€¼
        
        # ===== Anchorä¼˜åŒ– =====
        # YOLO11æ²¡æœ‰anchorï¼Œä½†å¯ä»¥è°ƒæ•´stride
        
        # ===== NMSè®¾ç½®====
        conf=0.001,    # è®­ç»ƒæ—¶çš„ç½®ä¿¡åº¦é˜ˆå€¼
        
        # ===== ä¿å­˜è®¾ç½® =====
        project=str(PROJECT_ROOT / "runs/detect"),
        name="yolo11_dust_optimized_v2",
        patience=100,  # å¢åŠ è€å¿ƒå€¼
        save=True,
        save_period=20,
        plots=True,
        val=True,
        
        # ===== EMAï¼ˆæŒ‡æ•°ç§»åŠ¨å¹³å‡ï¼‰=====
        # YOLO11é»˜è®¤å¯ç”¨
        
        # ===== å…¶ä»–ä¼˜åŒ– =====
        amp=True,
        fraction=1.0,
        overlap_mask=True,
        mask_ratio=4,
    )
    
    # ==================== æ­¥éª¤ 5: è¯„ä¼° ====================
    print("\n" + "="*70)
    print("æœ€ç»ˆè¯„ä¼°")
    print("="*70)
    
    best_model_path = results.save_dir / "weights/best.pt"
    best_model = YOLO(str(best_model_path))
    
    # å¤šä¸ªç½®ä¿¡åº¦é˜ˆå€¼æµ‹è¯•
    conf_thresholds = [0.001, 0.01, 0.05, 0.1]
    
    print("\nä¸åŒç½®ä¿¡åº¦é˜ˆå€¼çš„æ€§èƒ½ï¼š")
    for conf_th in conf_thresholds:
        val_results = best_model.val(
            data=str(DATASET_YAML),
            split='test',
            imgsz=640,
            batch=16,
            device='0' if torch.cuda.is_available() else 'cpu',
            conf=conf_th,
            iou=0.5,
            max_det=300,  # å¢åŠ æœ€å¤§æ£€æµ‹æ•°
            plots=False,
        )
        
        print(f"\nConf={conf_th:.3f} | mAP50={val_results.box.map50:.4f} | "
              f"P={val_results.box.mp:.4f} | R={val_results.box.mr:.4f}")
    
    # ä½¿ç”¨æœ€ä½³é˜ˆå€¼é‡æ–°è¯„ä¼°å¹¶ä¿å­˜å›¾åƒ
    val_results = best_model.val(
        data=str(DATASET_YAML),
        split='test',
        imgsz=640,
        batch=16,
        device='0' if torch.cuda.is_available() else 'cpu',
        conf=0.001,
        iou=0.5,
        max_det=300,
        plots=True,
        save_json=True,
    )
    
    print("\n" + "="*70)
    print("ğŸ“Š æœ€ç»ˆæµ‹è¯•ç»“æœ (conf=0.001)")
    print("="*70)
    print(f"mAP50:      {val_results.box.map50:.4f}")
    print(f"mAP50-95:   {val_results.box.map:.4f}")
    print(f"Precision:  {val_results.box.mp:.4f}")
    print(f"Recall:     {val_results.box.mr:.4f}")
    print("="*70)
    print(f"âœ… æœ€ä½³æ¨¡å‹: {best_model_path}")
    print(f"âœ… å¤„ç†åæ•°æ®: {PROCESSED_DATA_DIR}")
    print("="*70)