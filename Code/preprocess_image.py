import cv2
import numpy as np
import os
import shutil
import matplotlib.pyplot as plt
from pathlib import Path
from tqdm import tqdm

# ================= é…ç½®åŒºåŸŸ =================
# å…¨éƒ¨ä½¿ç”¨ç›¸å¯¹è·¯å¾„
INPUT_ROOT = r"./Data/Raw/dust"         # è¾“å…¥æ ¹ç›®å½•
OUTPUT_ROOT = r"./Data/Raw/dust_processed"  # è¾“å‡ºæ ¹ç›®å½•
TARGET_SIZE = (640, 640)                             # ç›®æ ‡å¤§å°

# ç®—æ³•å‚æ•°
CLAHE_CLIP_LIMIT = 2.0
CLAHE_GRID_SIZE = (8, 8)
BILATERAL_D = 9
BILATERAL_SIGMA_COLOR = 75
BILATERAL_SIGMA_SPACE = 75

# ================= æ ¸å¿ƒå¤„ç†é€»è¾‘ =================

def process_image_channels(img_path_str):
    """ç”Ÿæˆçš„å›¾ç‰‡é€šé“é¡ºåºï¼šCh0=åŸå›¾, Ch1=åŒè¾¹æ»¤æ³¢, Ch2=CLAHE"""
    img_gray = cv2.imread(img_path_str, 0)
    if img_gray is None: return None

    # 1. Lanczos æ’å€¼æ”¾å¤§ (64 -> 640)
    img_upscaled = cv2.resize(img_gray, TARGET_SIZE, interpolation=cv2.INTER_LANCZOS4)

    # 2. æ„å»ºé€šé“
    c0 = img_upscaled
    c1 = cv2.bilateralFilter(img_upscaled, d=BILATERAL_D, 
                             sigmaColor=BILATERAL_SIGMA_COLOR, 
                             sigmaSpace=BILATERAL_SIGMA_SPACE)
    clahe = cv2.createCLAHE(clipLimit=CLAHE_CLIP_LIMIT, tileGridSize=CLAHE_GRID_SIZE)
    c2 = clahe.apply(img_upscaled)

    # 3. åˆå¹¶ (BGR é¡ºåº)
    merged_img = cv2.merge([c0, c1, c2])
    return merged_img

def process_dataset(input_dir, output_dir):
    input_path = Path(input_dir)
    output_path = Path(output_dir)
    
    if not output_path.exists():
        os.makedirs(output_path)

    # é€’å½’è·å–æ‰€æœ‰æ–‡ä»¶
    files = [f for f in input_path.rglob('*') if f.is_file()]
    processed_count = 0

    print(f"ğŸš€ å¼€å§‹å¤„ç†æ•°æ®é›†ï¼Œç›®æ ‡å°ºå¯¸: {TARGET_SIZE}...")
    for file_path in tqdm(files, desc="Processing"):
        rel_path = file_path.relative_to(input_path)
        target_path = output_path / rel_path
        
        # æ’é™¤å·²æœ‰çš„ yaml æ–‡ä»¶
        if file_path.suffix.lower() == '.yaml':
            continue

        target_path.parent.mkdir(parents=True, exist_ok=True)

        # å¤„ç†å›¾ç‰‡
        if file_path.suffix.lower() in ['.jpg', '.jpeg', '.png', '.bmp', '.tif']:
            img = process_image_channels(str(file_path))
            if img is not None:
                save_path = target_path.with_suffix('.jpg') 
                cv2.imwrite(str(save_path), img)
                processed_count += 1
        
        # å¤åˆ¶æ ‡ç­¾æ–‡ä»¶ (.txt)
        elif file_path.suffix.lower() == '.txt':
            shutil.copy2(file_path, target_path)
    
    print(f"âœ… å¤„ç†å®Œæˆï¼Œå…±ç”Ÿæˆ {processed_count} å¼ å›¾åƒã€‚")

# ================= è¿è¡Œå…¥å£ =================
if __name__ == '__main__':
    if not os.path.exists(INPUT_ROOT):
        print(f"âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°è¾“å…¥ç›®å½• {INPUT_ROOT}")
    else:
        # 1. è¿è¡Œå¤„ç†æµç¨‹
        process_dataset(INPUT_ROOT, OUTPUT_ROOT)

        # 2. ç”Ÿæˆ dataset.yaml (ä½¿ç”¨ç›¸å¯¹è·¯å¾„)
        classes = ['dust']
        yaml_path = os.path.join(OUTPUT_ROOT, 'dataset.yaml')
        
        with open(yaml_path, 'w', encoding='utf-8') as f:
            # è¿™é‡Œçš„ path ä½¿ç”¨ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•çš„ç›¸å¯¹è·¯å¾„
            # æ³¨æ„ï¼šYOLO è®­ç»ƒæ—¶ï¼Œpath æ˜¯ç›¸å¯¹äºæ‰§è¡Œ train å‘½ä»¤çš„ç›®å½•
            f.write(f"path: {OUTPUT_ROOT}  # ç›¸å¯¹è·¯å¾„\n")
            f.write(f"train: images/train\n")
            f.write(f"val: images/val\n")
            f.write(f"test: images/test\n\n")
            
            f.write(f"nc: {len(classes)}\n")
            f.write(f"names: {str(classes)}\n")
        
        print(f'\n[DONE] é¢„å¤„ç†å®Œæˆï¼')
        print(f'ğŸ“ é…ç½®æ–‡ä»¶å·²ç”Ÿæˆ: {yaml_path}')
        print(f'ğŸ’¡ è¯·ç¡®ä¿åœ¨è®­ç»ƒè„šæœ¬ä¸­å¼•ç”¨æ­¤ç›¸å¯¹è·¯å¾„ã€‚')