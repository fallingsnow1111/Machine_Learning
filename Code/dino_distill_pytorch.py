"""
PyTorch åŸç”Ÿ DINOv3 -> YOLO11n çŸ¥è¯†è’¸é¦é¢„è®­ç»ƒè„šæœ¬

å®Œå…¨ç»•è¿‡ lightly-train å…¼å®¹æ€§é—®é¢˜ï¼Œä½¿ç”¨ PyTorch åŸç”Ÿ API å®ç°è’¸é¦ã€‚
å‚è€ƒ ziduo_test åˆ†æ”¯çš„ç›®æ ‡ï¼šé¢„è®­ç»ƒ YOLO11nï¼Œä¸ºåç»­æœ‰ç›‘ç£è®­ç»ƒæä¾›æ›´å¥½çš„åˆå§‹åŒ–æƒé‡ã€‚

ä½¿ç”¨æµç¨‹ï¼š
1. è¿è¡Œæ­¤è„šæœ¬è¿›è¡Œè’¸é¦é¢„è®­ç»ƒï¼ˆ150 epochsï¼‰
2. å°†è¾“å‡ºçš„æƒé‡ä¼ é€’ç»™ train_yolo11.py æˆ– dino_yolo.py
"""

import sys
import os
import tarfile
import tarfile
from pathlib import Path
from tqdm import tqdm

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import torchvision.transforms as transforms
from PIL import Image

# ==========================================
# è·¯å¾„é…ç½®
# ==========================================
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

print(f"ğŸ“‚ é¡¹ç›®æ ¹ç›®å½•: {PROJECT_ROOT}")

from ultralytics import YOLO
from modelscope import AutoModel
import os

# ==========================================
# ç®€å•å›¾åƒæ•°æ®é›†
# ==========================================
class SimpleImageDataset(torch.utils.data.Dataset):
    """åŠ è½½ç›®å½•ä¸­çš„æ‰€æœ‰å›¾åƒ"""
    def __init__(self, image_dir, transform=None):
        self.image_dir = Path(image_dir)
        self.image_files = list(self.image_dir.glob("*.jpg")) + \
                          list(self.image_dir.glob("*.png")) + \
                          list(self.image_dir.glob("*.jpeg"))
        self.transform = transform
    
    def __len__(self):
        return len(self.image_files)
    
    def __getitem__(self, idx):
        img_path = self.image_files[idx]
        try:
            image = Image.open(img_path).convert('RGB')
            if self.transform:
                image = self.transform(image)
            return image
        except Exception as e:
            print(f"âš ï¸ æ— æ³•åŠ è½½å›¾åƒ {img_path}: {e}")
            return torch.randn(3, 640, 640)

# ==========================================
# YOLO11 Backbone æå–å™¨
# ==========================================
class YOLO11BackboneExtractor(nn.Module):
    """æå– YOLO11n çš„ Backbone éƒ¨åˆ†"""
    def __init__(self, yolo_wrapper, layer_idx=10):
        super().__init__()
        # å…³é”®ä¿®å¤ï¼šyolo_wrapper.model æ˜¯ DetectionModelï¼Œyolo_wrapper.model.model æ‰æ˜¯ Sequential
        if hasattr(yolo_wrapper.model, 'model'):
            full_model = yolo_wrapper.model.model
        else:
            full_model = yolo_wrapper.model
            
        # æå–å‰ 10 å±‚ (0-9)ï¼ŒåŒ…å«åˆ° SPPF
        self.backbone = nn.Sequential(*list(full_model[:layer_idx]))
        
        # è‡ªåŠ¨å¯¹é½ç»´åº¦ï¼šYOLO11n å‡ºå£é€šå¸¸æ˜¯ 256ï¼ŒDINO-vitl16 æ˜¯ 1024
        self.adapter = nn.Sequential(
            nn.AdaptiveAvgPool2d((1, 1)),
            nn.Flatten(),
            nn.Linear(256, 1024)  # å¯¹åº” dino-vitl16  # å¯¹åº” dino-vitl16
            nn.Linear(256, 1024)  # å¯¹åº” dino-vitl16
        )
    
    def forward(self, x):
        """è¿”å›ç‰¹å¾å›¾å’Œå¯¹é½åçš„ç‰¹å¾å‘é‡"""
        feat_map = self.backbone(x)  # [B, 256, H, W]
        feat_vec = self.adapter(feat_map)  # [B, 1024]
        return feat_map, feat_vec

# ==========================================
# DINOv3 Teacher æ¨¡å‹
# ==========================================
class DINOv3Teacher(nn.Module):
    """DINOv3 ViT-L/16 ä½œä¸º Teacher"""
    def __init__(self, model_path=None):
        super().__init__()
        # æ™ºèƒ½è·¯å¾„æ£€æµ‹
        if model_path is None:
            # Kaggle vitl16 è·¯å¾„
            kaggle_path = '/kaggle/input/dinov3-vitl16/pytorch/default/1/dinov3-vitl16/facebook/dinov3-vitl16-pretrain-lvd1689m'
            if os.path.exists(kaggle_path):
                model_path = kaggle_path
                print(f"ğŸ“¥ åŠ è½½ Kaggle DINOv3 Teacher: {model_path}")
            else:
                # å¤‡é€‰è·¯å¾„
                model_path = '/kaggle/input/dinov3-vitl16/facebook/dinov3-vitl16'
                print(f"ğŸ“¥ åŠ è½½ DINOv3 Teacher (å¤‡é€‰): {model_path}")
        else:
            print(f"ğŸ“¥ åŠ è½½è‡ªå®šä¹‰è·¯å¾„ DINOv3 Teacher: {model_path}")
        
        from modelscope import AutoModel
        self.teacher = AutoModel.from_pretrained(model_path, trust_remote_code=True)
        self.teacher.eval()
        for param in self.teacher.parameters():
            param.requires_grad = False
    1024] å­¦ç”Ÿç‰¹å¾å‘é‡
    teacher_vec: [B, 102):
        """æå– DINO ç‰¹å¾"""
        with torch.no_grad():
            outputs = self.teacher(pixel_values=x, output_hidden_states=True)
            features = outputs.hidden_states[-1][:, 0, :]  # [B, 1024] CLS token
        return features

# ==========================================
# è’¸é¦æŸå¤±å‡½æ•°
# ==========================================
def compute_distill_loss(student_vec, teacher_vec, student_map):
    """
    è®¡ç®—è’¸é¦æŸå¤±
    student_vec: [B, 384] å­¦ç”Ÿç‰¹å¾å‘é‡
    teacher_vec: [B, 384] æ•™å¸ˆç‰¹å¾å‘é‡
    student_map: [B, 256, H, W] å­¦ç”Ÿç‰¹å¾å›¾
    """
    # 1. ä½™å¼¦ç›¸ä¼¼åº¦æŸå¤±ï¼ˆä¸»è¦è’¸é¦é¡¹ï¼‰
    cos_sim = torch.nn.functional.cosine_similarity(student_vec, teacher_vec).mean()
    distill_loss = 1 - cos_sim
    
    # 2. ç‰¹å¾å¤šæ ·æ€§æŸå¤±ï¼ˆé˜²æ­¢ç‰¹å¾åç¼©ï¼‰
    B, C, H, W = student_map.shape
    feat_flat = student_map.reshape(B, C, -1)
    var_loss = -torch.var(feat_flat, dim=[0, 2]).mean()
    
    return distill_loss + 0.1 * var_loss

def compute_simplified_loss(student_vec, student_map):
    """ç®€åŒ–çš„è‡ªç›‘ç£æŸå¤±ï¼ˆæ— éœ€ Teacherï¼‰"""
    # ç‰¹å¾å‘é‡çš„æ–¹å·®æŸå¤±
    B, D = student_vec.shape
    vec_var = torch.var(student_vec, dim=0).mean()
    var_loss = -vec_var
    
    # ç‰¹å¾èŒƒæ•°æŸå¤±ï¼ˆé˜²æ­¢ç‰¹å¾åå¡Œï¼‰
    norm_loss = torch.abs(student_vec.norm(dim=1) - 1.0).mean()
    
    return var_loss * 0.1 + norm_loss * 0.01

# ==========================================
# è’¸é¦é¢„è®­ç»ƒä¸»å‡½æ•°
# ==========================================
def run_distillation():
    """æ‰§è¡Œè’¸é¦é¢„è®­ç»ƒ"""
    
    # é…ç½®å‚æ•°
    DATA_DIR = PROJECT_ROOT / "Data" / "Merged" / "no_noise11_processed" / "images" / "train"
    OUTPUT_DIR = PROJECT_ROOT / "runs" / "distill" / "dinov3_yolo11n_pytorch"
    YOLO11N_PATH = PROJECT_ROOT / "pt" / "yolo11n.pt"  # YOLOæƒé‡ä¾ç„¶åœ¨ä»£ç ä»“å†…
    YOLO11N_PATH = PROJECT_ROOT / "pt" / "yolo11n.pt"  # YOLOæƒé‡ä¾ç„¶åœ¨ä»£ç ä»“å†…
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    
    EPOCHS = 150
    BATCH_SIZE = 16
    IMG_SIZE = 640
    LR = 1e-4
    
    # GPU è®¾å¤‡é…ç½®ï¼šè‡ªåŠ¨æ£€æµ‹åŒå¡
    gpu_count = torch.cuda.device_count()
    if gpu_count >= 2:
        DEVICE = "cuda"
        print(f"ğŸš€ æ£€æµ‹åˆ° {gpu_count} ä¸ª GPUï¼Œå¯ç”¨åŒå¡è’¸é¦")
    elif gpu_count == 1:
        DEVICE = "cuda"
        print(f"âš¡ å•å¡è’¸é¦")
    else:
        DEVICE = "cpu"
        print("âš ï¸ æœªæ£€æµ‹åˆ° GPUï¼Œä½¿ç”¨ CPU è’¸é¦")
    
    print("\n" + "="*60)
    print("ğŸš€ PyTorch åŸç”Ÿ DINOv3 -> YOLO11n è’¸é¦é¢„è®­ç»ƒ")
    print("="*60)
    print(f"ğŸ“ æ•°æ®ç›®å½•ï¼ˆä»£ç ä»“å†…ï¼‰: {DATA_DIR}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•ï¼ˆä»£ç ä»“å†…ï¼‰: {OUTPUT_DIR}")
    print(f"ğŸ“ æ•°æ®ç›®å½•ï¼ˆä»£ç ä»“å†…ï¼‰: {DATA_DIR}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•ï¼ˆä»£ç ä»“å†…ï¼‰: {OUTPUT_DIR}")
    print(f"ğŸ“Š è®­ç»ƒè½®æ•°: {EPOCHS}")
    print(f"ğŸ“Š æ‰¹æ¬¡å¤§å°: {BATCH_SIZE}")
    print(f"ğŸ’» è®¾å¤‡: {DEVICE}")
    print(f"ğŸ“¦ YOLO11nè·¯å¾„ï¼ˆä»£ç ä»“å†…ï¼‰: {YOLO11N_PATH}")
    print(f"ğŸ“¦ ViT-L/16è§£å‹ç›®å½•ï¼ˆç‹¬ç«‹ï¼‰: {DINO_EXTRACT_DIR}")
    print(f"ğŸ“¦ ViT-L/16æ¨¡å‹ç›®å½•ï¼ˆæ·±å±‚ï¼‰: {DINO_MODEL_DIR}")
    print(f"ğŸ“¦ YOLO11nè·¯å¾„ï¼ˆä»£ç ä»“å†…ï¼‰: {YOLO11N_PATH}")
    print(f"ğŸ“¦ ViT-L/16è§£å‹ç›®å½•ï¼ˆç‹¬ç«‹ï¼‰: {DINO_EXTRACT_DIR}")
    print(f"ğŸ“¦ ViT-L/16æ¨¡å‹ç›®å½•ï¼ˆæ·±å±‚ï¼‰: {DINO_MODEL_DIR}")
    print("="*60 + "\n")
    
    # æ£€æŸ¥æ•°æ®
    if not DATA_DIR.exists():
        print(f"âŒ æ•°æ®ç›®å½•ï¼ˆä»£ç ä»“å†…ï¼‰ä¸å­˜åœ¨: {DATA_DIR}")
        print("ğŸ’¡ è¯·ç¡®ä¿æ•°æ®å­˜æ”¾è·¯å¾„æ­£ç¡®ï¼Œæˆ–åˆ›å»ºå¯¹åº”ç›®å½•")
        DATA_DIR.mkdir(parents=True, exist_ok=True)
        print(f"âŒ æ•°æ®ç›®å½•ï¼ˆä»£ç ä»“å†…ï¼‰ä¸å­˜åœ¨: {DATA_DIR}")
        print("ğŸ’¡ è¯·ç¡®ä¿æ•°æ®å­˜æ”¾è·¯å¾„æ­£ç¡®ï¼Œæˆ–åˆ›å»ºå¯¹åº”ç›®å½•")
        DATA_DIR.mkdir(parents=True, exist_ok=True)
        sys.exit(1)
    
    # åŠ è½½æ¨¡å‹
    print("ğŸ“¦ åŠ è½½ YOLO11n...")
    yolo_wrapper = YOLO(str(PROJECT_ROOT / "pt" / "yolo11n.pt"))
    student = YOLO11BackboneExtractor(yolo_wrapper, layer_idx=10).to(DEVICE)
    
    # åŒå¡åˆ†å¸ƒå¼
    if gpu_count >= 2:
        student = nn.DataParallel(student)
    
    print("ğŸ“¦ åŠ è½½ DINOv3 Teacherï¼ˆç‹¬ç«‹ViTæ¨¡å‹ï¼‰...")
    print("ğŸ“¦ åŠ è½½ DINOv3 Teacherï¼ˆç‹¬ç«‹ViTæ¨¡å‹ï¼‰...")
    teacher = None
    try:
        # åŠ è½½ç‹¬ç«‹è·¯å¾„çš„ViTæ¨¡å‹ï¼Œä¸å½±å“ä»£ç ä»“å…¶ä»–é€»è¾‘
        teacher = DINOv3Teacher().to(DEVICE)
        print("âœ… DINOv3 vitl16 Teacher åŠ è½½æˆåŠŸ")
        # åŠ è½½ç‹¬ç«‹è·¯å¾„çš„ViTæ¨¡å‹ï¼Œä¸å½±å“ä»£ç ä»“å…¶ä»–é€»è¾‘
        teacher = DINOv3Teacher().to(DEVICE)
        print("âœ… DINOv3 vitl16 Teacher åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âš ï¸ æ— æ³•åŠ è½½ DINOv3: {e}")
        print("ä½¿ç”¨ç®€åŒ–çš„æŸå¤±å‡½æ•°è¿›è¡Œé¢„è®­ç»ƒ")
    
    # æ•°æ®åŠ è½½
    print("ğŸ“¦ å‡†å¤‡æ•°æ®...")
    transform = transforms.Compose([
        transforms.Resize((IMG_SIZE, IMG_SIZE)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], 
                           [0.229, 0.224, 0.225])
    ])
    
    dataset = SimpleImageDataset(DATA_DIR, transform=transform)
    # Jupyterç¯å¢ƒé€‚é…ï¼šnum_workers=0ï¼Œé¿å…å¤šè¿›ç¨‹æŠ¥é”™
    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)
    # Jupyterç¯å¢ƒé€‚é…ï¼šnum_workers=0ï¼Œé¿å…å¤šè¿›ç¨‹æŠ¥é”™
    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)
    
    if len(dataset) == 0:
        print(f"âŒ æ•°æ®é›†ï¼ˆä»£ç ä»“å†…ï¼‰ä¸ºç©º: {DATA_DIR}")
        print("ğŸ’¡ è¯·æ”¾å…¥å›¾åƒæ•°æ®åå†è¿è¡Œ")
        print(f"âŒ æ•°æ®é›†ï¼ˆä»£ç ä»“å†…ï¼‰ä¸ºç©º: {DATA_DIR}")
        print("ğŸ’¡ è¯·æ”¾å…¥å›¾åƒæ•°æ®åå†è¿è¡Œ")
        sys.exit(1)
    
    print(f"âœ… åŠ è½½ {len(dataset)} å¼ å›¾åƒï¼ˆä»£ç ä»“å†…æ•°æ®ï¼‰")
    print(f"âœ… åŠ è½½ {len(dataset)} å¼ å›¾åƒï¼ˆä»£ç ä»“å†…æ•°æ®ï¼‰")
    
    # ä¼˜åŒ–å™¨
    optimizer = optim.AdamW(student.parameters(), lr=LR, weight_decay=0.02)
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)
    
    # è®­ç»ƒå¾ªç¯
    print("\nğŸš€ å¼€å§‹è’¸é¦é¢„è®­ç»ƒ...")
    student.train()
    
    for epoch in range(EPOCHS):
        total_loss = 0.0
        pbar = tqdm(dataloader, desc=f"Epoch {epoch+1}/{EPOCHS}", unit="batch")
        
        for batch_idx, images in enumerate(pbar):
            images = images.to(DEVICE)
            
            # å­¦ç”Ÿå‰å‘
            student_map, student_vec = student(images)
            
            # å¦‚æœæœ‰ Teacherï¼Œä½¿ç”¨è’¸é¦æŸå¤±
            if teacher is not None:
                with torch.no_grad():
                    teacher_vec = teacher(images)
                loss = compute_distill_loss(student_vec, teacher_vec, student_map)
            else:
                # å¦åˆ™ä½¿ç”¨è‡ªç›‘ç£æŸå¤±
                loss = compute_simplified_loss(student_vec, student_map)
            
            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            loss.backward()
            torch.nn.utils.clip_grad_norm_(student.parameters(), max_norm=1.0)
            optimizer.step()
            
            total_loss += loss.item()
            pbar.set_postfix({"loss": f"{loss.item():.4f}"})
        
        # å­¦ä¹ ç‡è°ƒåº¦
        scheduler.step()
        avg_loss = total_loss / len(dataloader)
        
        if (epoch + 1) % 10 == 0:
            print(f"\nâœ… Epoch {epoch+1}/{EPOCHS} - Loss: {avg_loss:.4f}")
        
        # å®šæœŸä¿å­˜
        if (epoch + 1) % 50 == 0:
            checkpoint_path = OUTPUT_DIR / f"checkpoint_epoch{epoch+1}.pt"
            if isinstance(student, nn.DataParallel):
                torch.save(student.module.backbone.state_dict(), checkpoint_path)
            else:
                torch.save(student.backbone.state_dict(), checkpoint_path)
            print(f"ğŸ’¾ ä¿å­˜æ£€æŸ¥ç‚¹ï¼ˆä»£ç ä»“å†…ï¼‰: {checkpoint_path}")
            print(f"ğŸ’¾ ä¿å­˜æ£€æŸ¥ç‚¹ï¼ˆä»£ç ä»“å†…ï¼‰: {checkpoint_path}")
    
    # ä¿å­˜æœ€ç»ˆæƒé‡
    final_weights = OUTPUT_DIR / "yolo11n_distilled.pt"
    
    # è·å– backbone æƒé‡
    if isinstance(student, nn.DataParallel):
        backbone_state = student.module.backbone.state_dict()
    else:
        backbone_state = student.backbone.state_dict()
    
    # åŠ è½½å®Œæ•´ YOLO æ¨¡å‹
    complete_model = YOLO(str(PROJECT_ROOT / "pt" / "yolo11n.pt"))
    
    # è·å–å®Œæ•´æ¨¡å‹çš„ state_dict
    if hasattr(complete_model.model, 'model'):
        full_model = complete_model.model.model
    else:
        full_model = complete_model.model
    
    model_state = full_model.state_dict()
    
    # æ˜ å°„æƒé‡ï¼šbackbone çš„é”®æ˜¯ "0.weight", "1.weight" ç­‰
    print("\nğŸ”„ æ˜ å°„è’¸é¦æƒé‡åˆ°å®Œæ•´æ¨¡å‹...")
    for key, val in backbone_state.items():
        if key in model_state:
            model_state[key] = val
            print(f"âœ“ æ˜ å°„æƒé‡: {key}")
    
    # åŠ è½½å›æ¨¡å‹
    full_model.load_state_dict(model_state, strict=False)
    complete_model.save(str(final_weights))
    
    print(f"\nâœ… è’¸é¦é¢„è®­ç»ƒå®Œæˆï¼")
    print(f"ğŸ“ æƒé‡ä¿å­˜åœ¨ï¼ˆä»£ç ä»“å†…ï¼‰: {final_weights}")
    print(f"ğŸ“ æƒé‡ä¿å­˜åœ¨ï¼ˆä»£ç ä»“å†…ï¼‰: {final_weights}")
    print(f"\nğŸ’¡ ä½¿ç”¨æ–¹å¼ï¼š")
    print(f"   python Code/train_yolo11.py")
    print(f"   (è‡ªåŠ¨æ£€æµ‹å¹¶åŠ è½½è’¸é¦æƒé‡)")

# ==========================================
# ä¸»ç¨‹åºå…¥å£
# ==========================================
if __name__ == "__main__":
    try:
        run_distillation()
    except Exception as e:
        print(f"\nâŒ è’¸é¦é¢„è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
