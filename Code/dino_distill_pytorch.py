import sys
import os
import tarfile
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from pathlib import Path
from tqdm import tqdm
from torch.utils.data import DataLoader
import torchvision.transforms as transforms
from PIL import Image
from ultralytics import YOLO
from modelscope import AutoModel

# ===================== ğŸ“¡ è‡ªåŠ¨å¹³å°æ£€æµ‹ =====================
def detect_platform():
    if os.path.exists('/kaggle/working'): return "KAGGLE"
    if os.path.exists('/mnt/workspace'): return "ALIYUN"
    return "LOCAL"

PLATFORM = detect_platform()

# ===================== âš™ï¸ é…ç½®ç±» =====================
class Config:
    def __init__(self, mode):
        self.mode = mode
        try:
            self.project_root = Path(__file__).parent.parent
        except NameError:
            self.project_root = Path.cwd()
        
        self.relative_data_path = "Data/Merged/mixed_processed"
        self.data_dir = self.project_root / self.relative_data_path
        
        self.epochs = 150
        self.batch_size = 8  # ğŸš€ å»ºè®®è°ƒå°ä¸€ç‚¹ï¼Œé˜²æ­¢ä¸­å±‚ç‰¹å¾è’¸é¦ OOM
        self.img_size = 640
        self.lr = 1e-4
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        
        # æƒé‡é…æ¯”ï¼šç©ºé—´ç‰¹å¾ï¼ˆç»†èŠ‚ï¼‰å¯¹æ£€æµ‹æ›´é‡è¦
        self.lambda_global = 1.0  
        self.lambda_spatial = 5.0 # ğŸš€ MSE é€šå¸¸æ•°å€¼è¾ƒå°ï¼Œé€‚å½“æ‹‰é«˜æƒé‡

        if self.mode == "KAGGLE":
            self.output_dir = Path("/kaggle/working/runs/distill")
            self.yolo_pt_path = Path("/kaggle/working/yolo11n.pt")
            self.dino_model_path = Path("/kaggle/input/dinov3-vitl16/pytorch/default/1/dinov3-vitl16/facebook/dinov3-vitl16-pretrain-lvd1689m")
            self.dino_needs_extract = False
        else:
            self.output_dir = self.project_root / "runs/distill"
            self.yolo_pt_path = self.project_root / "pt/yolo11n.pt"
            self.dino_needs_extract = True
            self.dino_tar_path = Path("/mnt/workspace/dinov3-vitl16.tar.gz")
            self.dino_extract_dir = Path("/mnt/workspace/dinov3-vitl16")
            self.dino_model_path = None

    def check_env(self):
        self.output_dir.mkdir(parents=True, exist_ok=True)
        if not self.yolo_pt_path.exists():
            YOLO("yolo11n.pt").save(str(self.yolo_pt_path))

cfg = Config(PLATFORM)

# ===================== ğŸ§© æ¨¡å‹å®šä¹‰ =====================

class YOLO11Distiller(nn.Module):
    def __init__(self, yolo_path, layer_idx=10):
        super().__init__()
        yolo = YOLO(str(yolo_path))
        model_obj = yolo.model.model if hasattr(yolo.model, 'model') else yolo.model
        
        self.backbone = nn.Sequential(*list(model_obj[:layer_idx]))
        
        # ğŸš€ é‡ç‚¹ï¼šé€‚é…å™¨ç”¨äºå°† YOLO çš„ 256 é€šé“â€œç¿»è¯‘â€ç»™ DINO çœ‹
        self.spatial_adapter = nn.Conv2d(256, 1024, kernel_size=1)
        self.global_adapter = nn.Sequential(
            nn.AdaptiveAvgPool2d((1, 1)),
            nn.Flatten(),
            nn.Linear(256, 1024)
        )
    
    def forward(self, x):
        feat_map = self.backbone(x) 
        spatial_feat = self.spatial_adapter(feat_map)
        # ğŸš€ å½’ä¸€åŒ–ç‰¹å¾ï¼Œé˜²æ­¢ MSE æŸå¤±ç‚¸å¼€
        spatial_feat = F.normalize(spatial_feat, p=2, dim=1)
        global_feat = self.global_adapter(feat_map)
        global_feat = F.normalize(global_feat, p=2, dim=1)
        return spatial_feat, global_feat

class DINOv3Teacher(nn.Module):
    def __init__(self, config):
        super().__init__()
        # æ­¤å¤„çœç•¥ä½ ä¹‹å‰çš„ extract_tar_gz å’Œ find_config_dir å‡½æ•°é€»è¾‘
        path = config.dino_model_path if config.mode == "KAGGLE" else config.dino_extract_dir
        
        print(f"ğŸ“¥ æ­£åœ¨åŠ è½½æ•™å¸ˆæ¨¡å‹: {path}")
        self.teacher = AutoModel.from_pretrained(str(path), trust_remote_code=True)
        self.teacher.eval()
        for p in self.teacher.parameters(): p.requires_grad = False
    
    def forward(self, x):
        with torch.no_grad():
            outputs = self.teacher(pixel_values=x, output_hidden_states=True)
            last_hidden_state = outputs.hidden_states[-1] 
            
            # å…¨å±€ç‰¹å¾ (CLS)
            global_feat = F.normalize(last_hidden_state[:, 0, :], p=2, dim=1)
            
            # ç©ºé—´ç‰¹å¾ (Patch Tokens)
            patch_tokens = last_hidden_state[:, 1:, :] 
            b, n, c = patch_tokens.shape
            grid_size = int(n**0.5)
            spatial_feat = patch_tokens.transpose(1, 2).reshape(b, c, grid_size, grid_size)
            spatial_feat = F.normalize(spatial_feat, p=2, dim=1)
            
            return spatial_feat, global_feat

# ===================== ğŸš€ è®­ç»ƒé€»è¾‘ =====================

def run():
    cfg.check_env()
    
    teacher = DINOv3Teacher(cfg).to(cfg.device)
    student = YOLO11Distiller(cfg.yolo_pt_path).to(cfg.device)
    
    # ğŸš€ ä½¿ç”¨ AdamW å¹¶å¯¹é€‚é…å™¨å’Œ Backbone ç»Ÿä¸€ä¼˜åŒ–
    optimizer = optim.AdamW(student.parameters(), lr=cfg.lr, weight_decay=0.01)
    
    dataset = DataLoader(SimpleImageDataset(cfg.data_dir, transform=... ), batch_size=cfg.batch_size, shuffle=True)

    print("\nğŸ”¥ å¼€å§‹ä¸­å±‚ç‰¹å¾å¯¹é½è’¸é¦...")
    student.train()
    for epoch in range(cfg.epochs):
        loop = tqdm(dataset, desc=f"Epoch {epoch+1}/{cfg.epochs}")
        for img in loop:
            img = img.to(cfg.device)
            
            # ğŸš€ å»ºè®®ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ (AMP) èŠ‚çœæ˜¾å­˜
            with torch.cuda.amp.autocast():
                s_spatial, s_global = student(img)
                t_spatial, t_global = teacher(img)
                
                # ç¡®ä¿å°ºå¯¸ä¸€è‡´
                if s_spatial.shape[-2:] != t_spatial.shape[-2:]:
                    s_spatial = F.interpolate(s_spatial, size=t_spatial.shape[-2:], mode='bilinear')
                
                loss_g = 1 - F.cosine_similarity(s_global, t_global).mean()
                loss_s = F.mse_loss(s_spatial, t_spatial)
                loss = (cfg.lambda_global * loss_g) + (cfg.lambda_spatial * loss_s)
            
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            
            loop.set_postfix(loss=f"{loss.item():.4f}", s_loss=f"{loss_s.item():.4f}")

    # ===================== ğŸ’¾ å…³é”®ï¼šä¿å­˜é€»è¾‘ä¿®æ­£ =====================
    final_path = cfg.output_dir / "yolo11n_distilled.pt"
    # æˆ‘ä»¬åªæå– backbone çš„æƒé‡ï¼Œå¿½ç•¥é€‚é…å™¨
    pure_backbone_state = student.backbone.state_dict()
    
    full_yolo = YOLO(str(cfg.yolo_pt_path))
    # æ³¨å…¥æƒé‡
    full_yolo.model.model[:10].load_state_dict(pure_backbone_state)
    full_yolo.save(str(final_path))
    print(f"ğŸ‰ è’¸é¦åçš„éª¨å¹²ç½‘ç»œå·²æˆåŠŸæ³¨å…¥å¹¶ä¿å­˜è‡³: {final_path}")

if __name__ == "__main__":
    run()