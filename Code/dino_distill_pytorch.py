"""
PyTorch åŸç”Ÿ DINOv3 -> YOLO11n çŸ¥è¯†è’¸é¦é¢„è®­ç»ƒè„šæœ¬
ä½¿ç”¨ Kaggle vitl16 ä½œä¸ºæ•™å¸ˆæ¨¡å‹
"""

import sys
import os
from pathlib import Path
from tqdm import tqdm
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import torchvision.transforms as transforms
from PIL import Image

PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))
print(f"ğŸ“‚ é¡¹ç›®æ ¹ç›®å½•: {PROJECT_ROOT}")

from ultralytics import YOLO
from modelscope import AutoModel

class SimpleImageDataset(torch.utils.data.Dataset):
    def __init__(self, image_dir, transform=None):
        self.image_dir = Path(image_dir)
        self.image_files = list(self.image_dir.glob("*.jpg")) + \
                          list(self.image_dir.glob("*.png")) + \
                          list(self.image_dir.glob("*.jpeg"))
        self.transform = transform
    
    def __len__(self):
        return len(self.image_files)
    
    def __getitem__(self, idx):
        img_path = self.image_files[idx]
        try:
            image = Image.open(img_path).convert('RGB')
            if self.transform:
                image = self.transform(image)
            return image
        except:
            return torch.randn(3, 640, 640)

class YOLO11BackboneExtractor(nn.Module):
    def __init__(self, yolo_wrapper, layer_idx=10):
        super().__init__()
        if hasattr(yolo_wrapper.model, 'model'):
            full_model = yolo_wrapper.model.model
        else:
            full_model = yolo_wrapper.model
        
        self.backbone = nn.Sequential(*list(full_model[:layer_idx]))
        self.adapter = nn.Sequential(
            nn.AdaptiveAvgPool2d((1, 1)),
            nn.Flatten(),
            nn.Linear(256, 1024)
        )
    
    def forward(self, x):
        feat_map = self.backbone(x)
        feat_vec = self.adapter(feat_map)
        return feat_map, feat_vec

class DINOv3Teacher(nn.Module):
    def __init__(self, model_path=None):
        super().__init__()
        if model_path is None:
            kaggle_path = '/kaggle/input/dinov3-vitl16/pytorch/default/1/dinov3-vitl16/facebook/dinov3-vitl16-pretrain-lvd1689m'
            if os.path.exists(kaggle_path):
                model_path = kaggle_path
            else:
                model_path = '/kaggle/input/dinov3-vitl16/facebook/dinov3-vitl16'
        
        print(f"ğŸ“¥ åŠ è½½ DINOv3 Teacher: {model_path}")
        self.teacher = AutoModel.from_pretrained(model_path, trust_remote_code=True)
        self.teacher.eval()
        for param in self.teacher.parameters():
            param.requires_grad = False
    
    def forward(self, x):
        with torch.no_grad():
            outputs = self.teacher(pixel_values=x, output_hidden_states=True)
            features = outputs.hidden_states[-1][:, 0, :]
        return features

def compute_distill_loss(student_vec, teacher_vec, student_map):
    cos_sim = torch.nn.functional.cosine_similarity(student_vec, teacher_vec).mean()
    distill_loss = 1 - cos_sim
    
    B, C, H, W = student_map.shape
    feat_flat = student_map.reshape(B, C, -1)
    var_loss = -torch.var(feat_flat, dim=[0, 2]).mean()
    
    return distill_loss + 0.1 * var_loss

def compute_simplified_loss(student_vec, student_map):
    B, D = student_vec.shape
    vec_var = torch.var(student_vec, dim=0).mean()
    var_loss = -vec_var
    norm_loss = torch.abs(student_vec.norm(dim=1) - 1.0).mean()
    return var_loss * 0.1 + norm_loss * 0.01

def run_distillation():
    DATA_DIR = PROJECT_ROOT / "Data" / "Merged" / "no_noise11_processed" / "images" / "train"
    OUTPUT_DIR = PROJECT_ROOT / "runs" / "distill" / "dinov3_yolo11n_pytorch"
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    
    EPOCHS = 150
    BATCH_SIZE = 16
    IMG_SIZE = 640
    LR = 1e-4
    
    gpu_count = torch.cuda.device_count()
    if gpu_count >= 2:
        DEVICE = "cuda"
        print(f"ğŸš€ æ£€æµ‹åˆ° {gpu_count} ä¸ª GPUï¼Œå¯ç”¨åŒå¡è’¸é¦")
    elif gpu_count == 1:
        DEVICE = "cuda"
        print(f"âš¡ å•å¡è’¸é¦")
    else:
        DEVICE = "cpu"
        print("âš ï¸ æœªæ£€æµ‹åˆ° GPUï¼Œä½¿ç”¨ CPU è’¸é¦")
    
    print("\n" + "="*60)
    print("ğŸš€ PyTorch åŸç”Ÿ DINOv3 -> YOLO11n è’¸é¦é¢„è®­ç»ƒ")
    print("="*60)
    print(f"ğŸ“ æ•°æ®ç›®å½•: {DATA_DIR}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {OUTPUT_DIR}")
    print(f"ğŸ“Š è®­ç»ƒè½®æ•°: {EPOCHS}")
    print(f"ğŸ“Š æ‰¹æ¬¡å¤§å°: {BATCH_SIZE}")
    print(f"ğŸ’» è®¾å¤‡: {DEVICE}")
    print("="*60 + "\n")
    
    if not DATA_DIR.exists():
        print(f"âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {DATA_DIR}")
        sys.exit(1)
    
    print("ğŸ“¦ åŠ è½½ YOLO11n...")
    yolo_wrapper = YOLO(str(PROJECT_ROOT / "pt" / "yolo11n.pt"))
    student = YOLO11BackboneExtractor(yolo_wrapper, layer_idx=10).to(DEVICE)
    
    if gpu_count >= 2:
        student = nn.DataParallel(student)
    
    print("ğŸ“¦ åŠ è½½ DINOv3 Teacher...")
    teacher = None
    try:
        teacher = DINOv3Teacher().to(DEVICE)
        print("âœ… DINOv3 vitl16 Teacher åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âš ï¸ æ— æ³•åŠ è½½ DINOv3: {e}")
        print("ä½¿ç”¨ç®€åŒ–çš„æŸå¤±å‡½æ•°è¿›è¡Œé¢„è®­ç»ƒ")
    
    print("ğŸ“¦ å‡†å¤‡æ•°æ®...")
    transform = transforms.Compose([
        transforms.Resize((IMG_SIZE, IMG_SIZE)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    
    dataset = SimpleImageDataset(DATA_DIR, transform=transform)
    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)
    
    if len(dataset) == 0:
        print(f"âŒ æ•°æ®é›†ä¸ºç©º: {DATA_DIR}")
        sys.exit(1)
    
    print(f"âœ… åŠ è½½ {len(dataset)} å¼ å›¾åƒ")
    
    optimizer = optim.AdamW(student.parameters(), lr=LR, weight_decay=0.02)
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)
    
    print("\nğŸš€ å¼€å§‹è’¸é¦é¢„è®­ç»ƒ...")
    student.train()
    
    for epoch in range(EPOCHS):
        total_loss = 0.0
        pbar = tqdm(dataloader, desc=f"Epoch {epoch+1}/{EPOCHS}", unit="batch")
        
        for batch_idx, images in enumerate(pbar):
            images = images.to(DEVICE)
            
            student_map, student_vec = student(images)
            
            if teacher is not None:
                with torch.no_grad():
                    teacher_vec = teacher(images)
                loss = compute_distill_loss(student_vec, teacher_vec, student_map)
            else:
                loss = compute_simplified_loss(student_vec, student_map)
            
            optimizer.zero_grad()
            loss.backward()
            torch.nn.utils.clip_grad_norm_(student.parameters(), max_norm=1.0)
            optimizer.step()
            
            total_loss += loss.item()
            pbar.set_postfix({"loss": f"{loss.item():.4f}"})
        
        scheduler.step()
        avg_loss = total_loss / len(dataloader)
        
        if (epoch + 1) % 10 == 0:
            print(f"\nâœ… Epoch {epoch+1}/{EPOCHS} - Loss: {avg_loss:.4f}")
        
        if (epoch + 1) % 50 == 0:
            checkpoint_path = OUTPUT_DIR / f"checkpoint_epoch{epoch+1}.pt"
            if isinstance(student, nn.DataParallel):
                torch.save(student.module.backbone.state_dict(), checkpoint_path)
            else:
                torch.save(student.backbone.state_dict(), checkpoint_path)
            print(f"ğŸ’¾ ä¿å­˜æ£€æŸ¥ç‚¹: {checkpoint_path}")
    
    final_weights = OUTPUT_DIR / "yolo11n_distilled.pt"
    
    if isinstance(student, nn.DataParallel):
        backbone_state = student.module.backbone.state_dict()
    else:
        backbone_state = student.backbone.state_dict()
    
    complete_model = YOLO(str(PROJECT_ROOT / "pt" / "yolo11n.pt"))
    
    if hasattr(complete_model.model, 'model'):
        full_model = complete_model.model.model
    else:
        full_model = complete_model.model
    
    model_state = full_model.state_dict()
    
    print("\nğŸ”„ æ˜ å°„è’¸é¦æƒé‡åˆ°å®Œæ•´æ¨¡å‹...")
    for key, val in backbone_state.items():
        if key in model_state:
            model_state[key] = val
            print(f"âœ“ æ˜ å°„æƒé‡: {key}")
    
    full_model.load_state_dict(model_state, strict=False)
    complete_model.save(str(final_weights))
    
    print(f"\nâœ… è’¸é¦é¢„è®­ç»ƒå®Œæˆï¼")
    print(f"ğŸ“ æƒé‡ä¿å­˜åœ¨: {final_weights}")
    print(f"\nğŸ’¡ ä½¿ç”¨æ–¹å¼ï¼š")
    print(f"   python Code/train_yolo11.py")
    print(f"   (è‡ªåŠ¨æ£€æµ‹å¹¶åŠ è½½è’¸é¦æƒé‡)")

if __name__ == "__main__":
    try:
        run_distillation()
    except Exception as e:
        print(f"\nâŒ è’¸é¦é¢„è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
