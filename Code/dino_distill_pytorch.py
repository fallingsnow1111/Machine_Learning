"""
PyTorch åŸç”Ÿ DINOv3 -> YOLO11n çŸ¥è¯†è’¸é¦é¢„è®­ç»ƒè„šæœ¬
ä½¿ç”¨ Kaggle vitl16 ä½œä¸ºæ•™å¸ˆæ¨¡å‹
"""

import sys
import os
import tarfile
from pathlib import Path
from tqdm import tqdm
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import torchvision.transforms as transforms
from PIL import Image

# ===================== æ ¸å¿ƒï¼šè¿˜åŸé¡¹ç›®æ ¹ç›®å½•ï¼ˆä»£ç ä»“ç›®å½•ï¼Œå…¶ä»–è·¯å¾„å‡åŸºäºæ­¤ï¼‰ =====================
# å…¼å®¹Jupyterç¯å¢ƒï¼ˆ__file__ä¸å­˜åœ¨ï¼‰å’Œæ™®é€šPythonè„šæœ¬è¿è¡Œ
try:
    # æ™®é€šPythonè„šæœ¬ï¼šè·å–å½“å‰æ–‡ä»¶çš„çˆ¶çº§çˆ¶çº§ï¼ˆä»£ç ä»“çš„è·¯å¾„ç»“æ„ï¼‰
    PROJECT_ROOT = Path(__file__).parent.parent
except NameError:
    # Jupyterç¯å¢ƒï¼šä½¿ç”¨å½“å‰å·¥ä½œç›®å½•ä½œä¸ºä»£ç ä»“æ ¹ç›®å½•
    PROJECT_ROOT = Path.cwd()

sys.path.insert(0, str(PROJECT_ROOT))
print(f"ğŸ“‚ é¡¹ç›®ä»£ç ä»“æ ¹ç›®å½•: {PROJECT_ROOT}")

# ===================== ä»…ä¿®æ”¹è¿™é‡Œï¼šViT-L/16æ¨¡å‹è·¯å¾„é…ç½®ï¼ˆç‹¬ç«‹äºä»£ç ä»“ï¼‰ =====================
DINO_TAR_PATH = Path("/mnt/workspace/dinov3-vitl16.tar.gz")  # ä¸Šä¼ çš„æ¨¡å‹å‹ç¼©åŒ…è·¯å¾„
DINO_EXTRACT_DIR = Path("/mnt/workspace/dinov3-vitl16")  # æ¨¡å‹è§£å‹ç›®å½•

# ===================== è§£å‹å‡½æ•°ï¼ˆä»…ç”¨äºViTæ¨¡å‹ï¼‰ =====================
def extract_tar_gz(tar_path, extract_dir):
    """
    è§£å‹.tar.gzæ–‡ä»¶åˆ°æŒ‡å®šç›®å½•ï¼ˆä»…ç”¨äºViTæ¨¡å‹ï¼Œä¸å½±å“ä»£ç ä»“å…¶ä»–æ–‡ä»¶ï¼‰
    :param tar_path: .tar.gzå‹ç¼©åŒ…è·¯å¾„
    :param extract_dir: è§£å‹ç›®æ ‡ç›®å½•
    """
    extract_dir = Path(extract_dir)
    if extract_dir.exists():
        print(f"âœ… ViTæ¨¡å‹è§£å‹ç›®å½•å·²å­˜åœ¨ï¼Œæ— éœ€é‡å¤è§£å‹: {extract_dir}")
        return True
    
    # æ£€æŸ¥å‹ç¼©åŒ…æ˜¯å¦å­˜åœ¨
    if not tar_path.exists():
        print(f"âŒ ViTæ¨¡å‹å‹ç¼©åŒ…ä¸å­˜åœ¨: {tar_path}")
        return False
    
    try:
        with tarfile.open(tar_path, 'r:gz') as tar:
            # æ˜¾ç¤ºè§£å‹è¿›åº¦
            members = tar.getmembers()
            for member in tqdm(members, desc=f"è§£å‹ ViTæ¨¡å‹ {tar_path.name}"):
                tar.extract(member, extract_dir)
        print(f"âœ… ViTæ¨¡å‹è§£å‹å®Œæˆ: {extract_dir}")
        return True
    except Exception as e:
        print(f"âŒ ViTæ¨¡å‹è§£å‹å¤±è´¥: {e}")
        return False

from ultralytics import YOLO
from modelscope import AutoModel

class SimpleImageDataset(torch.utils.data.Dataset):
    def __init__(self, image_dir, transform=None):
        self.image_dir = Path(image_dir)
        self.image_files = list(self.image_dir.glob("*.jpg")) + \
                          list(self.image_dir.glob("*.png")) + \
                          list(self.image_dir.glob("*.jpeg"))
        self.transform = transform
    
    def __len__(self):
        return len(self.image_files)
    
    def __getitem__(self, idx):
        img_path = self.image_files[idx]
        try:
            image = Image.open(img_path).convert('RGB')
            if self.transform:
                image = self.transform(image)
            return image
        except:
            return torch.randn(3, 640, 640)

class YOLO11BackboneExtractor(nn.Module):
    def __init__(self, yolo_wrapper, layer_idx=10):
        super().__init__()
        if hasattr(yolo_wrapper.model, 'model'):
            full_model = yolo_wrapper.model.model
        else:
            full_model = yolo_wrapper.model
        
        self.backbone = nn.Sequential(*list(full_model[:layer_idx]))
        self.adapter = nn.Sequential(
            nn.AdaptiveAvgPool2d((1, 1)),
            nn.Flatten(),
            nn.Linear(256, 1024)
        )
    
    def forward(self, x):
        feat_map = self.backbone(x)
        feat_vec = self.adapter(feat_map)
        return feat_map, feat_vec

class DINOv3Teacher(nn.Module):
    def __init__(self, tar_path=DINO_TAR_PATH, extract_dir=DINO_EXTRACT_DIR):
        super().__init__()
        # ===================== ä»…ä¿®æ”¹ï¼šåŠ è½½ç‹¬ç«‹é…ç½®çš„ViTæ¨¡å‹è·¯å¾„ =====================
        print(f"ğŸ“¥ å‡†å¤‡åŠ è½½ViT-L/16æ¨¡å‹ï¼Œå‹ç¼©åŒ…è·¯å¾„: {tar_path}")
        
        # å…ˆè§£å‹ViTæ¨¡å‹ï¼ˆè§£å‹åˆ°ç‹¬ç«‹ç›®å½•ï¼Œä¸æ”¾å…¥ä»£ç ä»“ï¼‰
        if not extract_tar_gz(tar_path, extract_dir):
            raise Exception("ViTæ¨¡å‹å‹ç¼©åŒ…è§£å‹å¤±è´¥ï¼Œæ— æ³•åŠ è½½DINOv3 Teacher")
        
        # è§£å‹åçš„æ¨¡å‹è·¯å¾„ï¼ˆç”¨äºAutoModelåŠ è½½ï¼‰
        model_path = extract_dir
        print(f"ğŸ“¥ å¼€å§‹åŠ è½½ DINOv3 Teacher: {model_path}")
        
        self.teacher = AutoModel.from_pretrained(str(model_path), trust_remote_code=True)
        self.teacher.eval()
        for param in self.teacher.parameters():
            param.requires_grad = False
    
    def forward(self, x):
        with torch.no_grad():
            outputs = self.teacher(pixel_values=x, output_hidden_states=True)
            features = outputs.hidden_states[-1][:, 0, :]
        return features

def compute_distill_loss(student_vec, teacher_vec, student_map):
    cos_sim = torch.nn.functional.cosine_similarity(student_vec, teacher_vec).mean()
    distill_loss = 1 - cos_sim
    
    B, C, H, W = student_map.shape
    feat_flat = student_map.reshape(B, C, -1)
    var_loss = -torch.var(feat_flat, dim=[0, 2]).mean()
    
    return distill_loss + 0.1 * var_loss

def compute_simplified_loss(student_vec, student_map):
    B, D = student_vec.shape
    vec_var = torch.var(student_vec, dim=0).mean()
    var_loss = -vec_var
    norm_loss = torch.abs(student_vec.norm(dim=1) - 1.0).mean()
    return var_loss * 0.1 + norm_loss * 0.01

def run_distillation():
    # ===================== å®Œå…¨ä¿ç•™ï¼šä»£ç ä»“å†…çš„åŸæœ‰è·¯å¾„é€»è¾‘ =====================
    DATA_DIR = PROJECT_ROOT / "Data" / "Merged" / "no_noise11_processed" / "images" / "train"
    OUTPUT_DIR = PROJECT_ROOT / "runs" / "distill" / "dinov3_yolo11n_pytorch"
    YOLO11N_PATH = PROJECT_ROOT / "pt" / "yolo11n.pt"  # YOLOæƒé‡ä¾ç„¶åœ¨ä»£ç ä»“å†…
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    
    EPOCHS = 150
    BATCH_SIZE = 16
    IMG_SIZE = 640
    LR = 1e-4
    
    gpu_count = torch.cuda.device_count()
    if gpu_count >= 2:
        DEVICE = "cuda"
        print(f"ğŸš€ æ£€æµ‹åˆ° {gpu_count} ä¸ª GPUï¼Œå¯ç”¨åŒå¡è’¸é¦")
    elif gpu_count == 1:
        DEVICE = "cuda"
        print(f"âš¡ å•å¡è’¸é¦")
    else:
        DEVICE = "cpu"
        print("âš ï¸ æœªæ£€æµ‹åˆ° GPUï¼Œä½¿ç”¨ CPU è’¸é¦")
    
    print("\n" + "="*60)
    print("ğŸš€ PyTorch åŸç”Ÿ DINOv3 -> YOLO11n è’¸é¦é¢„è®­ç»ƒ")
    print("="*60)
    print(f"ğŸ“ æ•°æ®ç›®å½•ï¼ˆä»£ç ä»“å†…ï¼‰: {DATA_DIR}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•ï¼ˆä»£ç ä»“å†…ï¼‰: {OUTPUT_DIR}")
    print(f"ğŸ“Š è®­ç»ƒè½®æ•°: {EPOCHS}")
    print(f"ğŸ“Š æ‰¹æ¬¡å¤§å°: {BATCH_SIZE}")
    print(f"ğŸ’» è®¾å¤‡: {DEVICE}")
    print(f"ğŸ“¦ YOLO11nè·¯å¾„ï¼ˆä»£ç ä»“å†…ï¼‰: {YOLO11N_PATH}")
    print(f"ğŸ“¦ ViT-L/16æ¨¡å‹è·¯å¾„ï¼ˆç‹¬ç«‹ï¼‰: {DINO_EXTRACT_DIR}")
    print("="*60 + "\n")
    
    # æ£€æŸ¥ä»£ç ä»“å†…çš„æ•°æ®ç›®å½•æ˜¯å¦å­˜åœ¨
    if not DATA_DIR.exists():
        print(f"âŒ æ•°æ®ç›®å½•ï¼ˆä»£ç ä»“å†…ï¼‰ä¸å­˜åœ¨: {DATA_DIR}")
        print("ğŸ’¡ è¯·ç¡®ä¿æ•°æ®å­˜æ”¾è·¯å¾„æ­£ç¡®ï¼Œæˆ–åˆ›å»ºå¯¹åº”ç›®å½•")
        DATA_DIR.mkdir(parents=True, exist_ok=True)
        sys.exit(1)
    
    # æ£€æŸ¥ä»£ç ä»“å†…çš„YOLO11næƒé‡æ˜¯å¦å­˜åœ¨
    if not YOLO11N_PATH.exists():
        print(f"âš ï¸ YOLO11næƒé‡ï¼ˆä»£ç ä»“å†…ï¼‰ä¸å­˜åœ¨: {YOLO11N_PATH}")
        print("ğŸ’¡ æ­£åœ¨è‡ªåŠ¨ä¸‹è½½yolo11n.ptåˆ°ä»£ç ä»“ptç›®å½•...")
        YOLO11N_PATH.parent.mkdir(parents=True, exist_ok=True)
        yolo_temp = YOLO("yolo11n.pt")
        yolo_temp.save(str(YOLO11N_PATH))
    
    print("ğŸ“¦ åŠ è½½ YOLO11nï¼ˆä»£ç ä»“å†…æƒé‡ï¼‰...")
    yolo_wrapper = YOLO(str(YOLO11N_PATH))
    student = YOLO11BackboneExtractor(yolo_wrapper, layer_idx=10).to(DEVICE)
    
    if gpu_count >= 2:
        student = nn.DataParallel(student)
    
    print("ğŸ“¦ åŠ è½½ DINOv3 Teacherï¼ˆç‹¬ç«‹ViTæ¨¡å‹ï¼‰...")
    teacher = None
    try:
        # åŠ è½½ç‹¬ç«‹è·¯å¾„çš„ViTæ¨¡å‹ï¼Œä¸å½±å“ä»£ç ä»“å…¶ä»–é€»è¾‘
        teacher = DINOv3Teacher().to(DEVICE)
        print("âœ… DINOv3 vitl16 Teacher åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âš ï¸ æ— æ³•åŠ è½½ DINOv3: {e}")
        print("ä½¿ç”¨ç®€åŒ–çš„æŸå¤±å‡½æ•°è¿›è¡Œé¢„è®­ç»ƒ")
    
    print("ğŸ“¦ å‡†å¤‡æ•°æ®ï¼ˆä»£ç ä»“å†…æ•°æ®ï¼‰...")
    transform = transforms.Compose([
        transforms.Resize((IMG_SIZE, IMG_SIZE)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    
    dataset = SimpleImageDataset(DATA_DIR, transform=transform)
    # Jupyterç¯å¢ƒé€‚é…ï¼šnum_workers=0ï¼Œé¿å…å¤šè¿›ç¨‹æŠ¥é”™
    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)
    
    if len(dataset) == 0:
        print(f"âŒ æ•°æ®é›†ï¼ˆä»£ç ä»“å†…ï¼‰ä¸ºç©º: {DATA_DIR}")
        print("ğŸ’¡ è¯·æ”¾å…¥å›¾åƒæ•°æ®åå†è¿è¡Œ")
        sys.exit(1)
    
    print(f"âœ… åŠ è½½ {len(dataset)} å¼ å›¾åƒï¼ˆä»£ç ä»“å†…æ•°æ®ï¼‰")
    
    optimizer = optim.AdamW(student.parameters(), lr=LR, weight_decay=0.02)
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)
    
    print("\nğŸš€ å¼€å§‹è’¸é¦é¢„è®­ç»ƒ...")
    student.train()
    
    for epoch in range(EPOCHS):
        total_loss = 0.0
        pbar = tqdm(dataloader, desc=f"Epoch {epoch+1}/{EPOCHS}", unit="batch")
        
        for batch_idx, images in enumerate(pbar):
            images = images.to(DEVICE)
            
            student_map, student_vec = student(images)
            
            if teacher is not None:
                with torch.no_grad():
                    teacher_vec = teacher(images)
                loss = compute_distill_loss(student_vec, teacher_vec, student_map)
            else:
                loss = compute_simplified_loss(student_vec, student_map)
            
            optimizer.zero_grad()
            loss.backward()
            torch.nn.utils.clip_grad_norm_(student.parameters(), max_norm=1.0)
            optimizer.step()
            
            total_loss += loss.item()
            pbar.set_postfix({"loss": f"{loss.item():.4f}"})
        
        scheduler.step()
        avg_loss = total_loss / len(dataloader)
        
        if (epoch + 1) % 10 == 0:
            print(f"\nâœ… Epoch {epoch+1}/{EPOCHS} - Loss: {avg_loss:.4f}")
        
        if (epoch + 1) % 50 == 0:
            checkpoint_path = OUTPUT_DIR / f"checkpoint_epoch{epoch+1}.pt"
            if isinstance(student, nn.DataParallel):
                torch.save(student.module.backbone.state_dict(), checkpoint_path)
            else:
                torch.save(student.backbone.state_dict(), checkpoint_path)
            print(f"ğŸ’¾ ä¿å­˜æ£€æŸ¥ç‚¹ï¼ˆä»£ç ä»“å†…ï¼‰: {checkpoint_path}")
    
    final_weights = OUTPUT_DIR / "yolo11n_distilled.pt"
    
    if isinstance(student, nn.DataParallel):
        backbone_state = student.module.backbone.state_dict()
    else:
        backbone_state = student.backbone.state_dict()
    
    complete_model = YOLO(str(YOLO11N_PATH))
    
    if hasattr(complete_model.model, 'model'):
        full_model = complete_model.model.model
    else:
        full_model = complete_model.model
    
    model_state = full_model.state_dict()
    
    print("\nğŸ”„ æ˜ å°„è’¸é¦æƒé‡åˆ°å®Œæ•´æ¨¡å‹ï¼ˆä»£ç ä»“å†…ï¼‰...")
    for key, val in backbone_state.items():
        if key in model_state:
            model_state[key] = val
            print(f"âœ“ æ˜ å°„æƒé‡: {key}")
    
    full_model.load_state_dict(model_state, strict=False)
    complete_model.save(str(final_weights))
    
    print(f"\nâœ… è’¸é¦é¢„è®­ç»ƒå®Œæˆï¼")
    print(f"ğŸ“ æƒé‡ä¿å­˜åœ¨ï¼ˆä»£ç ä»“å†…ï¼‰: {final_weights}")
    print(f"\nğŸ’¡ ä½¿ç”¨æ–¹å¼ï¼š")
    print(f"   python Code/train_yolo11.py")
    print(f"   (è‡ªåŠ¨æ£€æµ‹å¹¶åŠ è½½ä»£ç ä»“å†…çš„è’¸é¦æƒé‡)")

if __name__ == "__main__":
    try:
        run_distillation()
    except Exception as e:
        print(f"\nâŒ è’¸é¦é¢„è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
