"""
PyTorch åŸç”Ÿ DINOv3 -> YOLO11n çŸ¥è¯†è’¸é¦é¢„è®­ç»ƒè„šæœ¬

å®Œå…¨ç»•è¿‡ lightly-train å…¼å®¹æ€§é—®é¢˜ï¼Œä½¿ç”¨ PyTorch åŸç”Ÿ API å®ç°è’¸é¦ã€‚
å‚è€ƒ ziduo_test åˆ†æ”¯çš„ç›®æ ‡ï¼šé¢„è®­ç»ƒ YOLO11nï¼Œä¸ºåç»­æœ‰ç›‘ç£è®­ç»ƒæä¾›æ›´å¥½çš„åˆå§‹åŒ–æƒé‡ã€‚

ä½¿ç”¨æµç¨‹ï¼š
1. è¿è¡Œæ­¤è„šæœ¬è¿›è¡Œè’¸é¦é¢„è®­ç»ƒï¼ˆ150 epochsï¼‰
2. å°†è¾“å‡ºçš„æƒé‡ä¼ é€’ç»™ train_yolo11.py æˆ– dino_yolo.py
"""

import sys
import os
from pathlib import Path
from tqdm import tqdm

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import torchvision.transforms as transforms
from PIL import Image
import numpy as np

# ==========================================
# è·¯å¾„é…ç½®
# ==========================================
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

print(f"ğŸ“‚ é¡¹ç›®æ ¹ç›®å½•: {PROJECT_ROOT}")

from ultralytics import YOLO
from transformers import AutoModel

# ==========================================
# ç®€å•å›¾åƒæ•°æ®é›†
# ==========================================
class SimpleImageDataset(torch.utils.data.Dataset):
    """åŠ è½½ç›®å½•ä¸­çš„æ‰€æœ‰å›¾åƒ"""
    def __init__(self, image_dir, transform=None):
        self.image_dir = Path(image_dir)
        self.image_files = list(self.image_dir.glob("*.jpg")) + \
                          list(self.image_dir.glob("*.png")) + \
                          list(self.image_dir.glob("*.jpeg"))
        self.transform = transform
    
    def __len__(self):
        return len(self.image_files)
    
    def __getitem__(self, idx):
        img_path = self.image_files[idx]
        try:
            image = Image.open(img_path).convert('RGB')
            if self.transform:
                image = self.transform(image)
            return image
        except Exception as e:
            print(f"âš ï¸ æ— æ³•åŠ è½½å›¾åƒ {img_path}: {e}")
            # è¿”å›éšæœºå¼ é‡ä½œä¸ºå¤‡é€‰
            return torch.randn(3, 640, 640)

# ==========================================
# YOLO11 Backbone æå–å™¨
# ==========================================
class YOLO11BackboneExtractor(nn.Module):
    """æå– YOLO11n çš„ Backbone éƒ¨åˆ†"""
    def __init__(self, yolo_wrapper, layer_idx=10):
        super().__init__()
        # å…³é”®ä¿®å¤ï¼šyolo_wrapper.model æ˜¯ DetectionModelï¼Œyolo_wrapper.model.model æ‰æ˜¯ Sequential
        if hasattr(yolo_wrapper.model, 'model'):
            full_model = yolo_wrapper.model.model
        else:
            full_model = yolo_wrapper.model
            
        # æå–å‰ 10 å±‚ (0-9)ï¼ŒåŒ…å«åˆ° SPPF
        self.backbone = nn.Sequential(*list(full_model[:layer_idx]))
        
        # è‡ªåŠ¨å¯¹é½ç»´åº¦ï¼šYOLO11n å‡ºå£é€šå¸¸æ˜¯ 256ï¼ŒDINO-Tiny æ˜¯ 384
        self.adapter = nn.Sequential(
            nn.AdaptiveAvgPool2d((1, 1)),
            nn.Flatten(),
            nn.Linear(256, 384)  # å¯¹åº” dino-vit-tiny-16
        )
    
    def forward(self, x):
        """è¿”å›å¯¹é½åçš„ç‰¹å¾å‘é‡ [B, 384]"""
        features = self.backbone(x)  # [B, 256, H, W]
        return self.adapter(features)  # [B, 384]

# ==========================================
# DINOv3 Teacher æ¨¡å‹
# ==========================================
class DINOv3Teacher(nn.Module):
    """DINOv3 ViT-Tiny/16 ä½œä¸º Teacher"""
    def __init__(self, model_name="facebook/dino-vitb16"):
        super().__init__()
        print(f"ğŸ“¥ åŠ è½½ DINOv3 Teacher: {model_name}")
        self.teacher = AutoModel.from_pretrained(model_name)
        self.teacher.eval()  # å†»ç»“ Teacher
        for param in self.teacher.parameters():
            param.requires_grad = False
    
    def forward(self, x):
        """æå– DINO ç‰¹å¾"""
        with torch.no_grad():
            # DINO è¾“å‡º [B, N, 384]ï¼ˆN æ˜¯ patch æ•°ï¼‰
            outputs = self.teacher(x)
            # å– CLS token ç‰¹å¾
            features = outputs.last_hidden_state[:, 0, :]  # [B, 384]
        return features

# ==========================================
# è’¸é¦æŸå¤±å‡½æ•°
# ==========================================
def distillation_loss(student_features, teacher_features, temperature=4.0):
    """
    ç®€å•çš„è’¸é¦æŸå¤±ï¼šæœ€å°åŒ–å­¦ç”Ÿå’Œæ•™å¸ˆç‰¹å¾çš„ KL æ•£åº¦
    """
    # å­¦ç”Ÿç‰¹å¾ï¼š[B, 256, H, W] -> [B, 256]ï¼ˆå…¨å±€æ± åŒ–ï¼‰
    student_pool = torch.nn.functional.adaptive_avg_pool2d(student_features, (1, 1)).flatten(1)
    
    # æŠ•å½±åˆ°ç›¸åŒç»´åº¦ï¼ˆ384ï¼‰
    student_proj = student_pool  # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…å¯åŠ çº¿æ€§å±‚
    teacher_feat = teacher_features  # [B, 384]
    
    # å½’ä¸€åŒ–
    student_norm = torch.nn.functional.normalize(student_proj, dim=1)
    teacher_norm = torch.nn.functional.normalize(teacher_feat, dim=1)
    
    # ä½™å¼¦ç›¸ä¼¼åº¦æŸå¤±
    loss = 1 - (student_norm * teacher_norm).sum(dim=1).mean()
    
    return loss

# ==========================================
# è’¸é¦é¢„è®­ç»ƒä¸»å‡½æ•°
# ==========================================
def run_distillation():
    """æ‰§è¡Œè’¸é¦é¢„è®­ç»ƒ"""
    
    # é…ç½®å‚æ•°
    DATA_DIR = PROJECT_ROOT / "Data" / "Merged" / "no_noise11_processed" / "images" / "train"
    OUTPUT_DIR = PROJECT_ROOT / "runs" / "distill" / "dinov3_yolo11n_pytorch"
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    
    EPOCHS = 150
    BATCH_SIZE = 16
    IMG_SIZE = 640
    LR = 1e-4
    
    # GPU è®¾å¤‡é…ç½®ï¼šè‡ªåŠ¨æ£€æµ‹åŒå¡
    gpu_count = torch.cuda.device_count()
    if gpu_count >= 2:
        DEVICE = "cuda"  # åŒå¡è‡ªåŠ¨åˆ†å¸ƒ
        print(f"ğŸš€ æ£€æµ‹åˆ° {gpu_count} ä¸ª GPUï¼Œå¯ç”¨åŒå¡è’¸é¦")
    elif gpu_count == 1:
        DEVICE = "cuda"
        print(f"âš¡ å•å¡è’¸é¦")
    else:
        DEVICE = "cpu"
        print("âš ï¸ æœªæ£€æµ‹åˆ° GPUï¼Œä½¿ç”¨ CPU è’¸é¦")
    
    print("\n" + "="*60)
    print("ğŸš€ PyTorch åŸç”Ÿ DINOv3 -> YOLO11n è’¸é¦é¢„è®­ç»ƒ")
    print("="*60)
    print(f"ğŸ“ æ•°æ®ç›®å½•: {DATA_DIR}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {OUTPUT_DIR}"), layer_idx=10
    print(f"ğŸ“Š è®­ç»ƒè½®æ•°: {EPOCHS}")
    print(f"ğŸ“Š æ‰¹æ¬¡å¤§å°: {BATCH_SIZE}")
    print(f"ğŸ’» è®¾å¤‡: {DEVICE}")
    print("="*60 + "\n")
    
    # æ£€æŸ¥æ•°æ®
    if not DATA_DIR.exists():
        print(f"âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {DATA_DIR}")
        sys.exit(1)
    
    # åŠ è½½æ¨¡å‹
    print("ğŸ“¦ åŠ è½½ YOLO11n...")
    yolo_wrapper = YOLO(str(PROJECT_ROOT / "pt" / "yolo11n.pt"))
    student = YOLO11BackboneExtractor(yolo_wrapper).to(DEVICE)
    
    # åŒå¡åˆ†å¸ƒå¼
    if gpu_count >= 2:
        student = nn.DataParallel(student)
    
    print("ğŸ“¦ åŠ è½½ DINOv3 Teacher...")
    # æ³¨æ„ï¼šDINOv3 éœ€è¦æ¥è‡ª HuggingFaceï¼Œè¿™é‡Œä½¿ç”¨ç®€åŒ–çš„åŠ è½½
    # å®é™…å¯ä»¥ç”¨ï¼šteacher = DINOv3Teacher("facebook/dino-vit-tiny-16")
    teacher = None
    try:
        teacher = DINOv3Teacher("facebook/dino-vit-tiny-16").to(DEVICE)
    except Exception as e:
        print(f"âš ï¸ æ— æ³•åŠ è½½ DINOv3: {e}")
        print("ä½¿ç”¨ç®€åŒ–çš„æŸå¤±å‡½æ•°è¿›è¡Œé¢„è®­ç»ƒ")
    
    # æ•°æ®åŠ è½½
    print("ğŸ“¦ å‡†å¤‡æ•°æ®...")
    transform = transforms.Compose([
        transforms.Resize((IMG_SIZE, IMG_SIZE)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], 
                           [0.229, 0.224, 0.225])
    ])
    
    dataset = SimpleImageDataset(DATA_DIR, transform=transform)
    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)
    
    if len(dataset) == 0:
        print(f"âŒ æ•°æ®é›†ä¸ºç©º: {DATA_DIR}")
        sys.exit(1)
    
    print(f"âœ… åŠ è½½ {len(dataset)} å¼ å›¾åƒ")
    
    # ä¼˜åŒ–å™¨
    optimizer = optim.AdamW(student.parameters(), lr=LR, weight_decay=0.02)
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)
    
    # è®­ç»ƒå¾ªç¯
    print("\nğŸš€ å¼€å§‹è’¸é¦é¢„è®­ç»ƒ...")
    student.train()
    
    for epoch in range(EPOCHS):
        total_loss = 0.0
        pbar = tqdm(dataloader, desc=f"Epoch {epoch+1}/{EPOCHS}", unit="batch")
        
        for batch_idx, images in enumerate(pbar):
            images = images.to(DEVICE)
            
            # å­¦ç”Ÿå‰å‘
            student_features = student(images)  # [B, 384]
            
            # å¦‚æœæœ‰ Teacherï¼Œä½¿ç”¨è’¸é¦æŸå¤±
            if teacher is not None:
                with torch.no_grad():
                    teacher_features = teacher(images)  # [B, 384]
                # ä½™å¼¦ç›¸ä¼¼åº¦æŸå¤±
                loss = 1 - torch.nn.functional.cosine_similarity(student_features, teacher_features).mean()
            else:
                # å¦åˆ™ä½¿ç”¨è‡ªç›‘ç£æŸå¤±
                loss = compute_simplified_loss(student_features)
            
            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            loss.backward()
            torch.nn.utils.clip_grad_norm_(student.parameters(), max_norm=1.0)
            optimizer.step()
            
            total_loss += loss.item()
            pbar.set_postfix({"loss": f"{loss.item():.4f}"})
        
        # å­¦ä¹ ç‡è°ƒåº¦
        scheduler.step()
        avg_loss = total_loss / len(dataloader)
        
        if (epoch + 1) % 10 == 0:
            print(f"\nâœ… Epoch {epoch+1}/{EPOCHS} - Loss: {avg_loss:.4f}")
        
        # å®šæœŸä¿å­˜
        if (epoch + 1) % 50 == 0:
            checkpoint_path = OUTPUT_DIR / f"checkpoint_epoch{epoch+1}.pt"
            # å¤„ç† DataParallel æƒ…å†µ
            if isinstance(student, nn.DataParallel):
                torch.save(student.module.backbone.state_dict(), checkpoint_path)
            else:
                torch.save(student.backbone.state_dict(), checkpoint_path)
            print(f"ğŸ’¾ ä¿å­˜æ£€æŸ¥ç‚¹: {checkpoint_path}")
    
    # ä¿å­˜æœ€ç»ˆæƒé‡
    final_weights = OUTPUT_DIR / "yolo11n_distilled.pt"
    
    
    # åŠ è½½å®Œæ•´ YOLO æ¨¡å‹
    complete_model = YOLO(str(PROJECT_ROOT / "pt" / "yolo11n.pt"))
    
    # è·å–å®Œæ•´æ¨¡å‹çš„ state_dict
    if hasattr(complete_model.model, 'model'):
        full_model = complete_model.model.model
    else:
        full_model = complete_model.model
    
    model_state = full_model.state_dict()
    
    # æ˜ å°„æƒé‡ï¼šbackbone çš„é”®æ˜¯ "0.weight", "1.weight" ç­‰
    for key, val in backbone_state.items():
        if key in model_state:
            model_state[key] = val
            print(f"âœ“ æ˜ å°„æƒé‡: {key}")
    
    # åŠ è½½å›æ¨¡å‹
    full_ backbone_state.items():
        # åœ¨ model ä¸­æŸ¥æ‰¾å¯¹åº”çš„é”®
        model_key = f"model.{key}"
        if model_key in model_state:
            model_state[model_key] = val
    
    complete_model.model.load_state_dict(model_state, strict=False)
    complete_model.save(str(final_weights))
    print(f"\nâœ… è’¸é¦é¢„è®­ç»ƒå®Œæˆï¼")
    print(f"ğŸ“ æƒé‡ä¿å­˜åœ¨: {final_weights}")
    print(f"\nğŸ’¡ ä½¿ç”¨æ–¹å¼ï¼š")
    print(f"   from ultraly- ç”¨äºç‰¹å¾å‘é‡"""
    # features: [B, 384]
    B, D = features.shape
    
    # ç‰¹å¾æ–¹å·®æŸå¤±ï¼šé¼“åŠ±å¤šæ ·åŒ–ç‰¹å¾
    feat_var = torch.var(features, dim=0)
    var_loss = -feat_var.mean()  # æœ€å¤§åŒ–æ–¹å·®
    
    # ç‰¹å¾èŒƒæ•°æŸå¤±ï¼šé˜²æ­¢ç‰¹å¾åç¼©
    norm_loss = torch.abs(features.norm(dim=1) - 1.0).mean()
    
    return var_loss * 0.1 + norm_loss * 0.01ape(B, C, -1)  # [B, C, HW]
    
    # è®¡ç®—æ¯ä¸ªé€šé“çš„æ–¹å·®
    feat_var = torch.var(features_flat, dim=[0, 2])
    var_loss = -feat_var.mean()  # æœ€å¤§åŒ–æ–¹å·®
    
    return var_loss * 0.1  # æƒé‡è°ƒæ•´

# ==========================================
# ä¸»ç¨‹åºå…¥å£
# ==========================================
if __name__ == "__main__":
    try:
        run_distillation()
    except Exception as e:
        print(f"\nâŒ è’¸é¦é¢„è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
